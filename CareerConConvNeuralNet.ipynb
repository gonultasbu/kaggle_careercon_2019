{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Dropout, Conv1D, Flatten, MaxPooling1D, Concatenate, Multiply, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.manifold import TSNE\n",
    "import lightgbm as lgb\n",
    "import math\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "import matplotlib\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "np.random.seed(203)\n",
    "import math\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please consider upvoting this kernel if you find it helpful in any way. And don't hesitate to ask any questions on why I'm doing what I'm doing. And finally (most importantly), please point out if I'm being dumb anywhere below so that I can fix it :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "targets = pd.read_csv(\"y_train.csv\")\n",
    "df_train = pd.read_csv(\"X_train.csv\")\n",
    "df_test = pd.read_csv(\"X_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, I wanted to see how much predictive power the series had without any feature engineering. My plan on doing this was to create a Neural Net with multiple inputs (One for each 128 observation feature). With quite a lot of parameter tuning and regularization, the model was able to consistently achieve a CV accuracy between 61 and 67.\n",
    "\n",
    "I then realized that to the model, certain textures were very similar (it kept on confusing the same classes). I wanted more features to be able to distinguish between these classes with a higher accuracy. Therefore, my goal was to create new features that aimed to establish the \"smoothness\" of all the readings. My hypthesis was that the smoothness of readings would help distinguish between similar classes. What are the \"smoothness\" features though? Firstly, the standard deviation of the differences between consecutive readings (a perfectly straight line will have a standard deviation of 0 because the differences are constant), and secondly, for more polynomial looking lines, the RMSE from the moving average of the line (If a set of readings has a lot of spikes, ie. isn't smooth, then the error wil be large).\n",
    "\n",
    "Now, moving on to the actual code. In this first section, I'm just extracting all the values from the pandas dataframe and reshaping the resulting numpy array into its individual series (Plus rescaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.get_dummies(targets, columns=[\"surface\"])\n",
    "Y = targets.drop([\"series_id\", \"group_id\"], axis=1).values\n",
    "X = df_train.drop([\"row_id\", \"series_id\", \"measurement_number\"], axis=1).values\n",
    "test = df_test.drop([\"row_id\", \"series_id\", \"measurement_number\"], axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = X.reshape((3810, 128, 10, 1))\n",
    "X = X.transpose(0, 2, 1, 3)\n",
    "test = scaler.transform(test)\n",
    "test = test.reshape((3816, 128, 10, 1))\n",
    "test = test.transpose(0, 2, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block, I'm using some pandas tricks to obtain the aforementioned \"smoothness\" features from the test and train dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every column gets the smoothness features, except for the ones in the list below\n",
    "for col in df_train.drop([\"row_id\", \"series_id\", \"measurement_number\"], axis=1).columns:\n",
    "    df_train[\"diff_\"+col] = df_train[col]-df_train[col].shift(1)\n",
    "    df_test[\"diff_\"+col] = df_test[col]-df_test[col].shift(1)\n",
    "    df_train[\"ma_\"+col] = np.square(abs(df_train[col]-df_train[col].rolling(8).mean()))\n",
    "    df_test[\"ma_\"+col] = np.square(abs(df_test[col]-df_test[col].rolling(8).mean()))\n",
    "\n",
    "# The first 8 measurement (0-7) contain data from the previous series id (because of the rolling mean), \n",
    "# so they have to be dropped\n",
    "df_train = df_train[df_train[\"measurement_number\"]>7]\n",
    "df_test = df_test[df_test[\"measurement_number\"]>7]\n",
    "\n",
    "aggs = {\n",
    "    \"diff_orientation_X\":\"std\",\n",
    "    \"diff_orientation_Y\":\"std\",\n",
    "    \"diff_orientation_Z\":\"std\",\n",
    "    \"diff_orientation_W\":\"std\",\n",
    "    \"diff_angular_velocity_X\":\"std\",\n",
    "    \"diff_angular_velocity_Y\":\"std\",\n",
    "    \"diff_angular_velocity_Z\":\"std\",\n",
    "    \"diff_linear_acceleration_X\":\"std\",\n",
    "    \"diff_linear_acceleration_Y\":\"std\",\n",
    "    \"diff_linear_acceleration_Z\":\"std\",\n",
    "    \"ma_orientation_X\":\"sum\",\n",
    "    \"ma_orientation_Y\":\"sum\",\n",
    "    \"ma_orientation_Z\":\"sum\",\n",
    "    \"ma_orientation_W\":\"sum\",\n",
    "    \"ma_angular_velocity_X\":\"sum\",\n",
    "    \"ma_angular_velocity_Y\":\"sum\",\n",
    "    \"ma_angular_velocity_Z\":\"sum\",\n",
    "    \"ma_linear_acceleration_X\":\"sum\",\n",
    "    \"ma_linear_acceleration_Y\":\"sum\",\n",
    "    \"ma_linear_acceleration_Z\":\"sum\"\n",
    "}\n",
    "\n",
    "train_smooth = df_train.groupby(\"series_id\").agg(aggs)\n",
    "test_smooth = df_test.groupby(\"series_id\").agg(aggs)\n",
    "train_smooth.reset_index(inplace=True)\n",
    "test_smooth.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a quick check to ensure that the features turned out okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3810, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>diff_orientation_X</th>\n",
       "      <th>diff_orientation_Y</th>\n",
       "      <th>diff_orientation_Z</th>\n",
       "      <th>diff_orientation_W</th>\n",
       "      <th>diff_angular_velocity_X</th>\n",
       "      <th>diff_angular_velocity_Y</th>\n",
       "      <th>diff_angular_velocity_Z</th>\n",
       "      <th>diff_linear_acceleration_X</th>\n",
       "      <th>diff_linear_acceleration_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>ma_orientation_X</th>\n",
       "      <th>ma_orientation_Y</th>\n",
       "      <th>ma_orientation_Z</th>\n",
       "      <th>ma_orientation_W</th>\n",
       "      <th>ma_angular_velocity_X</th>\n",
       "      <th>ma_angular_velocity_Y</th>\n",
       "      <th>ma_angular_velocity_Z</th>\n",
       "      <th>ma_linear_acceleration_X</th>\n",
       "      <th>ma_linear_acceleration_Y</th>\n",
       "      <th>ma_linear_acceleration_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.038691</td>\n",
       "      <td>0.028768</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.922267</td>\n",
       "      <td>0.670404</td>\n",
       "      <td>...</td>\n",
       "      <td>3.812828e-07</td>\n",
       "      <td>4.730125e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.157107</td>\n",
       "      <td>0.066516</td>\n",
       "      <td>0.015078</td>\n",
       "      <td>47.416411</td>\n",
       "      <td>54.790411</td>\n",
       "      <td>129.126698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>1.545196</td>\n",
       "      <td>1.353271</td>\n",
       "      <td>...</td>\n",
       "      <td>5.527609e-07</td>\n",
       "      <td>6.335519e-06</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.528547</td>\n",
       "      <td>0.249689</td>\n",
       "      <td>0.363267</td>\n",
       "      <td>113.848545</td>\n",
       "      <td>138.833410</td>\n",
       "      <td>450.217492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.033881</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>1.132570</td>\n",
       "      <td>0.979919</td>\n",
       "      <td>...</td>\n",
       "      <td>2.602950e-06</td>\n",
       "      <td>8.248469e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.164368</td>\n",
       "      <td>0.140227</td>\n",
       "      <td>0.035255</td>\n",
       "      <td>53.033779</td>\n",
       "      <td>144.875970</td>\n",
       "      <td>114.053852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.126241</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>2.060239</td>\n",
       "      <td>2.278828</td>\n",
       "      <td>...</td>\n",
       "      <td>4.103109e-07</td>\n",
       "      <td>2.022280e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>1.441615</td>\n",
       "      <td>0.223097</td>\n",
       "      <td>0.059015</td>\n",
       "      <td>199.561159</td>\n",
       "      <td>556.261437</td>\n",
       "      <td>934.213309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.008092</td>\n",
       "      <td>0.256040</td>\n",
       "      <td>0.370395</td>\n",
       "      <td>...</td>\n",
       "      <td>9.975125e-06</td>\n",
       "      <td>4.312642e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.091879</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.056375</td>\n",
       "      <td>11.054523</td>\n",
       "      <td>32.276311</td>\n",
       "      <td>66.197295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  diff_orientation_X  diff_orientation_Y  diff_orientation_Z  \\\n",
       "0          0            0.000019            0.000020            0.000064   \n",
       "1          1            0.000029            0.000083            0.000065   \n",
       "2          2            0.000031            0.000018            0.000069   \n",
       "3          3            0.000032            0.000046            0.000079   \n",
       "4          4            0.000022            0.000043            0.000028   \n",
       "\n",
       "   diff_orientation_W  diff_angular_velocity_X  diff_angular_velocity_Y  \\\n",
       "0            0.000053                 0.038691                 0.028768   \n",
       "1            0.000130                 0.076469                 0.057924   \n",
       "2            0.000056                 0.033881                 0.044900   \n",
       "3            0.000236                 0.126241                 0.054900   \n",
       "4            0.000057                 0.028686                 0.012247   \n",
       "\n",
       "   diff_angular_velocity_Z  diff_linear_acceleration_X  \\\n",
       "0                 0.011237                    0.922267   \n",
       "1                 0.025305                    1.545196   \n",
       "2                 0.016317                    1.132570   \n",
       "3                 0.022548                    2.060239   \n",
       "4                 0.008092                    0.256040   \n",
       "\n",
       "   diff_linear_acceleration_Y  ...  ma_orientation_X  ma_orientation_Y  \\\n",
       "0                    0.670404  ...      3.812828e-07      4.730125e-07   \n",
       "1                    1.353271  ...      5.527609e-07      6.335519e-06   \n",
       "2                    0.979919  ...      2.602950e-06      8.248469e-07   \n",
       "3                    2.278828  ...      4.103109e-07      2.022280e-06   \n",
       "4                    0.370395  ...      9.975125e-06      4.312642e-05   \n",
       "\n",
       "   ma_orientation_Z  ma_orientation_W  ma_angular_velocity_X  \\\n",
       "0          0.000003          0.000001               0.157107   \n",
       "1          0.000002          0.000006               0.528547   \n",
       "2          0.000004          0.000002               0.164368   \n",
       "3          0.000003          0.000029               1.441615   \n",
       "4          0.000002          0.000002               0.091879   \n",
       "\n",
       "   ma_angular_velocity_Y  ma_angular_velocity_Z  ma_linear_acceleration_X  \\\n",
       "0               0.066516               0.015078                 47.416411   \n",
       "1               0.249689               0.363267                113.848545   \n",
       "2               0.140227               0.035255                 53.033779   \n",
       "3               0.223097               0.059015                199.561159   \n",
       "4               0.017231               0.056375                 11.054523   \n",
       "\n",
       "   ma_linear_acceleration_Y  ma_linear_acceleration_Z  \n",
       "0                 54.790411                129.126698  \n",
       "1                138.833410                450.217492  \n",
       "2                144.875970                114.053852  \n",
       "3                556.261437                934.213309  \n",
       "4                 32.276311                 66.197295  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_smooth.shape) #should be (3810, 20), because 10 columns got 2 additional features each\n",
    "train_smooth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_smooth = train_smooth.drop([\"series_id\"], axis=1).values\n",
    "test_smooth = test_smooth.drop([\"series_id\"], axis=1).values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_smooth = scaler.fit_transform(X_smooth)\n",
    "test_smooth = scaler.transform(test_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to the fun part, building and training a Convolutional Neural Network and reformatting the input so that the CNN can train on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    \n",
    "    #These features occur frequently throughout, so for easu of use, it's easier to change them up here.\n",
    "    FIRST = 30 #20\n",
    "    SECOND = 20 #10\n",
    "    HEIGHT1 = 4 #4\n",
    "    HEIGHT2 = 3 #4\n",
    "    DROPOUT = 0.5\n",
    "    STRIDES = None\n",
    "    PS = 5\n",
    "    \n",
    "    input1 = Input(shape=(128, 1))\n",
    "    a = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input1)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPooling1D(strides=STRIDES, pool_size=PS)(a)\n",
    "    a = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(a)\n",
    "    a = BatchNormalization()(a)\n",
    "    a = MaxPooling1D(strides=STRIDES, pool_size=PS)(a)\n",
    "    a = Flatten()(a)\n",
    "    a = Dropout(DROPOUT)(a)\n",
    "\n",
    "    input2 = Input(shape=(128, 1))\n",
    "    b = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input2)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPooling1D(strides=STRIDES, pool_size=PS)(b)\n",
    "    b = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(b)\n",
    "    b = BatchNormalization()(b)\n",
    "    b = MaxPooling1D(strides=STRIDES, pool_size=PS)(b)\n",
    "    b = Flatten()(b)\n",
    "    b = Dropout(DROPOUT)(b)\n",
    "\n",
    "    input3 = Input(shape=(128, 1))\n",
    "    c = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input3)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPooling1D(strides=STRIDES, pool_size=PS)(c)\n",
    "    c = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(c)\n",
    "    c = BatchNormalization()(c)\n",
    "    c = MaxPooling1D(strides=STRIDES, pool_size=PS)(c)\n",
    "    c = Flatten()(c)\n",
    "    c = Dropout(DROPOUT)(c)\n",
    "\n",
    "    input4 = Input(shape=(128, 1))\n",
    "    d = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input4)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPooling1D(strides=STRIDES, pool_size=PS)(d)\n",
    "    d = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = MaxPooling1D(strides=STRIDES, pool_size=PS)(d)\n",
    "    d = Flatten()(d)\n",
    "    d = Dropout(DROPOUT)(d)\n",
    "\n",
    "    input5 = Input(shape=(128, 1))\n",
    "    e = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input5)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = MaxPooling1D(strides=STRIDES, pool_size=PS)(e)\n",
    "    e = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(e)\n",
    "    e = BatchNormalization()(e)\n",
    "    e = MaxPooling1D(strides=STRIDES, pool_size=PS)(e)\n",
    "    e = Flatten()(e)\n",
    "    e = Dropout(DROPOUT)(e)\n",
    "\n",
    "    input6 = Input(shape=(128, 1))\n",
    "    f = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input6)\n",
    "    f = BatchNormalization()(f)\n",
    "    f = MaxPooling1D(strides=STRIDES, pool_size=PS)(f)\n",
    "    f = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(f)\n",
    "    f = BatchNormalization()(f)\n",
    "    f = MaxPooling1D(strides=STRIDES, pool_size=PS)(f)\n",
    "    f = Flatten()(f)\n",
    "    f = Dropout(DROPOUT)(f)\n",
    "\n",
    "    input7 = Input(shape=(128, 1))\n",
    "    g = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input7)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = MaxPooling1D(strides=STRIDES, pool_size=PS)(g)\n",
    "    g = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(g)\n",
    "    g = BatchNormalization()(g)\n",
    "    g = MaxPooling1D(strides=STRIDES, pool_size=PS)(g)\n",
    "    g = Flatten()(g)\n",
    "    g = Dropout(DROPOUT)(g)\n",
    "\n",
    "    input8 = Input(shape=(128, 1))\n",
    "    h = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input8)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = MaxPooling1D(strides=STRIDES, pool_size=PS)(h)\n",
    "    h = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(h)\n",
    "    h = BatchNormalization()(h)\n",
    "    h = MaxPooling1D(strides=STRIDES, pool_size=PS)(h)\n",
    "    h = Flatten()(h)\n",
    "    h = Dropout(DROPOUT)(h)\n",
    "\n",
    "    input9 = Input(shape=(128, 1))\n",
    "    i = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input9)\n",
    "    i = BatchNormalization()(i)\n",
    "    i = MaxPooling1D(strides=STRIDES, pool_size=PS)(i)\n",
    "    i = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(i)\n",
    "    i = BatchNormalization()(i)\n",
    "    i = MaxPooling1D(strides=STRIDES, pool_size=PS)(i)\n",
    "    i = Flatten()(i)\n",
    "    i = Dropout(DROPOUT)(i)\n",
    "\n",
    "    input10 = Input(shape=(128, 1))\n",
    "    j = Conv1D(FIRST, HEIGHT1, activation=\"relu\", kernel_initializer=\"uniform\")(input10)\n",
    "    j = BatchNormalization()(j)\n",
    "    j = MaxPooling1D(strides=STRIDES, pool_size=PS)(j)\n",
    "    j = Conv1D(SECOND, HEIGHT2, activation=\"relu\", kernel_initializer=\"uniform\")(j)\n",
    "    j = BatchNormalization()(j)\n",
    "    j = MaxPooling1D(strides=STRIDES, pool_size=PS)(j)\n",
    "    j = Flatten()(j)\n",
    "    j = Dropout(DROPOUT)(j)\n",
    "    \n",
    "    input11 = Input(shape=(20,))\n",
    "    k = Dense(30, activation=\"relu\", kernel_initializer=\"uniform\")(input11)\n",
    "    k = Dropout(0.25)(k)\n",
    "\n",
    "    merged = Concatenate()([a, b])\n",
    "    merged = Concatenate()([merged, c])\n",
    "    merged = Concatenate()([merged, d])\n",
    "    merged = Concatenate()([merged, e])\n",
    "    merged = Concatenate()([merged, f])\n",
    "    merged = Concatenate()([merged, g])\n",
    "    merged = Concatenate()([merged, h])\n",
    "    merged = Concatenate()([merged, i])\n",
    "    merged = Concatenate()([merged, j])\n",
    "    merged = Concatenate()([merged, k])\n",
    "    merged = Dense(30, activation = \"relu\", kernel_initializer=\"uniform\")(merged)\n",
    "    merged = Dropout(0.25)(merged)\n",
    "    \n",
    "    output = Dense(9, activation=\"softmax\", kernel_initializer=\"uniform\")(merged)\n",
    "    model = Model([input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11], output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the LB score is almost always better with a higher number of folds. (Be warned, this might take a few hours to train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING:tensorflow:From c:\\users\\mert\\anaconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\users\\mert\\anaconda3\\envs\\ml_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\mert\\anaconda3\\envs\\ml_env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3552 samples, validate on 258 samples\n",
      "Epoch 1/50\n",
      "3552/3552 [==============================] - 14s 4ms/step - loss: 1.6594 - acc: 0.4091 - val_loss: 1.3364 - val_acc: 0.5039\n",
      "Epoch 2/50\n",
      "3552/3552 [==============================] - 3s 891us/step - loss: 1.3268 - acc: 0.5287 - val_loss: 1.1115 - val_acc: 0.6240\n",
      "Epoch 3/50\n",
      "3552/3552 [==============================] - 3s 882us/step - loss: 1.2084 - acc: 0.5681 - val_loss: 1.0887 - val_acc: 0.6124\n",
      "Epoch 4/50\n",
      "3552/3552 [==============================] - 3s 884us/step - loss: 1.0958 - acc: 0.6101 - val_loss: 0.9390 - val_acc: 0.6667\n",
      "Epoch 5/50\n",
      "3552/3552 [==============================] - 3s 895us/step - loss: 1.0378 - acc: 0.6292 - val_loss: 0.9330 - val_acc: 0.6395\n",
      "Epoch 6/50\n",
      "3552/3552 [==============================] - 3s 886us/step - loss: 0.9805 - acc: 0.6489 - val_loss: 0.8194 - val_acc: 0.7054\n",
      "Epoch 7/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.9604 - acc: 0.6557 - val_loss: 0.8046 - val_acc: 0.7248\n",
      "Epoch 8/50\n",
      "3552/3552 [==============================] - 3s 882us/step - loss: 0.9299 - acc: 0.6630 - val_loss: 0.8393 - val_acc: 0.7287\n",
      "Epoch 9/50\n",
      "3552/3552 [==============================] - 3s 885us/step - loss: 0.9046 - acc: 0.6712 - val_loss: 0.7962 - val_acc: 0.7364\n",
      "Epoch 10/50\n",
      "3552/3552 [==============================] - 3s 888us/step - loss: 0.8571 - acc: 0.6881 - val_loss: 0.8260 - val_acc: 0.6705\n",
      "Epoch 11/50\n",
      "3552/3552 [==============================] - 3s 879us/step - loss: 0.8657 - acc: 0.6889 - val_loss: 0.7078 - val_acc: 0.7248\n",
      "Epoch 12/50\n",
      "3552/3552 [==============================] - 3s 886us/step - loss: 0.8175 - acc: 0.7106 - val_loss: 0.6587 - val_acc: 0.7713\n",
      "Epoch 13/50\n",
      "3552/3552 [==============================] - 3s 896us/step - loss: 0.8132 - acc: 0.7030 - val_loss: 0.6804 - val_acc: 0.7442\n",
      "Epoch 14/50\n",
      "3552/3552 [==============================] - 3s 897us/step - loss: 0.8183 - acc: 0.6931 - val_loss: 0.7287 - val_acc: 0.7364\n",
      "Epoch 15/50\n",
      "3552/3552 [==============================] - 3s 885us/step - loss: 0.7690 - acc: 0.7244 - val_loss: 0.6513 - val_acc: 0.7674\n",
      "Epoch 16/50\n",
      "3552/3552 [==============================] - 3s 879us/step - loss: 0.7521 - acc: 0.7269 - val_loss: 0.6327 - val_acc: 0.7713\n",
      "Epoch 17/50\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.7794 - acc: 0.7157 - val_loss: 0.6704 - val_acc: 0.7674\n",
      "Epoch 18/50\n",
      "3552/3552 [==============================] - 3s 894us/step - loss: 0.7532 - acc: 0.7283 - val_loss: 0.6339 - val_acc: 0.7713\n",
      "Epoch 19/50\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.7460 - acc: 0.7373 - val_loss: 0.6144 - val_acc: 0.8023\n",
      "Epoch 20/50\n",
      "3552/3552 [==============================] - 3s 887us/step - loss: 0.7157 - acc: 0.7399 - val_loss: 0.6138 - val_acc: 0.7791\n",
      "Epoch 21/50\n",
      "3552/3552 [==============================] - 3s 886us/step - loss: 0.7085 - acc: 0.7466 - val_loss: 0.6230 - val_acc: 0.7674\n",
      "Epoch 22/50\n",
      "3552/3552 [==============================] - 3s 891us/step - loss: 0.7028 - acc: 0.7379 - val_loss: 0.5988 - val_acc: 0.7597\n",
      "Epoch 23/50\n",
      "3552/3552 [==============================] - 3s 893us/step - loss: 0.6969 - acc: 0.7432 - val_loss: 0.6750 - val_acc: 0.7829\n",
      "Epoch 24/50\n",
      "3552/3552 [==============================] - 3s 892us/step - loss: 0.6919 - acc: 0.7469 - val_loss: 0.5791 - val_acc: 0.8101\n",
      "Epoch 25/50\n",
      "3552/3552 [==============================] - 3s 900us/step - loss: 0.6854 - acc: 0.7472 - val_loss: 0.5921 - val_acc: 0.8101\n",
      "Epoch 26/50\n",
      "3552/3552 [==============================] - 3s 904us/step - loss: 0.6723 - acc: 0.7593 - val_loss: 0.6653 - val_acc: 0.7752\n",
      "Epoch 27/50\n",
      "3552/3552 [==============================] - 3s 890us/step - loss: 0.7097 - acc: 0.7463 - val_loss: 0.6250 - val_acc: 0.7946\n",
      "Epoch 28/50\n",
      "3552/3552 [==============================] - 3s 899us/step - loss: 0.6906 - acc: 0.7469 - val_loss: 0.6358 - val_acc: 0.7829\n",
      "Epoch 29/50\n",
      "3552/3552 [==============================] - 3s 907us/step - loss: 0.6678 - acc: 0.7573 - val_loss: 0.5649 - val_acc: 0.7907\n",
      "Epoch 30/50\n",
      "3552/3552 [==============================] - 3s 892us/step - loss: 0.6370 - acc: 0.7736 - val_loss: 0.5931 - val_acc: 0.7868\n",
      "Epoch 31/50\n",
      "3552/3552 [==============================] - 3s 884us/step - loss: 0.6265 - acc: 0.7689 - val_loss: 0.5560 - val_acc: 0.8101\n",
      "Epoch 32/50\n",
      "3552/3552 [==============================] - 3s 905us/step - loss: 0.6294 - acc: 0.7655 - val_loss: 0.5724 - val_acc: 0.8178\n",
      "Epoch 33/50\n",
      "3552/3552 [==============================] - 3s 888us/step - loss: 0.6462 - acc: 0.7596 - val_loss: 0.5475 - val_acc: 0.7868\n",
      "Epoch 34/50\n",
      "3552/3552 [==============================] - 3s 880us/step - loss: 0.6223 - acc: 0.7720 - val_loss: 0.5549 - val_acc: 0.8256\n",
      "Epoch 35/50\n",
      "3552/3552 [==============================] - 3s 904us/step - loss: 0.6166 - acc: 0.7838 - val_loss: 0.6117 - val_acc: 0.7868\n",
      "Epoch 36/50\n",
      "3552/3552 [==============================] - 3s 897us/step - loss: 0.6008 - acc: 0.7787 - val_loss: 0.5882 - val_acc: 0.7829\n",
      "Epoch 37/50\n",
      "3552/3552 [==============================] - 3s 886us/step - loss: 0.5906 - acc: 0.7838 - val_loss: 0.5541 - val_acc: 0.7829\n",
      "Epoch 38/50\n",
      "3552/3552 [==============================] - 3s 895us/step - loss: 0.6061 - acc: 0.7728 - val_loss: 0.5154 - val_acc: 0.8101\n",
      "Epoch 39/50\n",
      "3552/3552 [==============================] - 3s 884us/step - loss: 0.6163 - acc: 0.7711 - val_loss: 0.6162 - val_acc: 0.7829\n",
      "Epoch 40/50\n",
      "3552/3552 [==============================] - 3s 880us/step - loss: 0.6081 - acc: 0.7798 - val_loss: 0.5750 - val_acc: 0.8062\n",
      "Epoch 41/50\n",
      "3552/3552 [==============================] - 3s 881us/step - loss: 0.6071 - acc: 0.7731 - val_loss: 0.5262 - val_acc: 0.8062\n",
      "Epoch 42/50\n",
      "3552/3552 [==============================] - 3s 886us/step - loss: 0.5872 - acc: 0.7877 - val_loss: 0.6381 - val_acc: 0.7713\n",
      "Epoch 43/50\n",
      "3552/3552 [==============================] - 3s 881us/step - loss: 0.6132 - acc: 0.7751 - val_loss: 0.5966 - val_acc: 0.7713\n",
      "Epoch 44/50\n",
      "3552/3552 [==============================] - 3s 882us/step - loss: 0.5921 - acc: 0.7762 - val_loss: 0.5535 - val_acc: 0.7868\n",
      "Epoch 45/50\n",
      "3552/3552 [==============================] - 3s 889us/step - loss: 0.5697 - acc: 0.7767 - val_loss: 0.5454 - val_acc: 0.8178\n",
      "Epoch 46/50\n",
      "3552/3552 [==============================] - 3s 887us/step - loss: 0.5937 - acc: 0.7793 - val_loss: 0.5609 - val_acc: 0.8101\n",
      "Epoch 47/50\n",
      "3552/3552 [==============================] - 3s 883us/step - loss: 0.5653 - acc: 0.7922 - val_loss: 0.5656 - val_acc: 0.8062\n",
      "Epoch 48/50\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.5849 - acc: 0.7894 - val_loss: 0.6509 - val_acc: 0.8140\n",
      "Epoch 49/50\n",
      "3552/3552 [==============================] - 3s 902us/step - loss: 0.5655 - acc: 0.7917 - val_loss: 0.5427 - val_acc: 0.8101\n",
      "Epoch 50/50\n",
      "3552/3552 [==============================] - 3s 902us/step - loss: 0.5653 - acc: 0.7922 - val_loss: 0.5964 - val_acc: 0.7907\n",
      "1\n",
      "Train on 3552 samples, validate on 258 samples\n",
      "Epoch 1/50\n",
      "3552/3552 [==============================] - 10s 3ms/step - loss: 1.6163 - acc: 0.4307 - val_loss: 1.3771 - val_acc: 0.5078\n",
      "Epoch 2/50\n",
      "3552/3552 [==============================] - 3s 922us/step - loss: 1.2860 - acc: 0.5456 - val_loss: 1.1343 - val_acc: 0.6240\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552/3552 [==============================] - 3s 911us/step - loss: 1.1628 - acc: 0.5904 - val_loss: 1.0725 - val_acc: 0.6473\n",
      "Epoch 4/50\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 1.0683 - acc: 0.6287 - val_loss: 1.0129 - val_acc: 0.6550\n",
      "Epoch 5/50\n",
      "3552/3552 [==============================] - 3s 914us/step - loss: 1.0056 - acc: 0.6503 - val_loss: 0.9314 - val_acc: 0.6938\n",
      "Epoch 6/50\n",
      "3552/3552 [==============================] - 3s 909us/step - loss: 0.9560 - acc: 0.6593 - val_loss: 0.9373 - val_acc: 0.6783\n",
      "Epoch 7/50\n",
      "3552/3552 [==============================] - 3s 895us/step - loss: 0.9317 - acc: 0.6658 - val_loss: 0.8230 - val_acc: 0.7248\n",
      "Epoch 8/50\n",
      "3552/3552 [==============================] - 3s 906us/step - loss: 0.9028 - acc: 0.6805 - val_loss: 0.8417 - val_acc: 0.6938\n",
      "Epoch 9/50\n",
      "3552/3552 [==============================] - 3s 896us/step - loss: 0.8639 - acc: 0.7016 - val_loss: 0.7494 - val_acc: 0.7326\n",
      "Epoch 10/50\n",
      "3552/3552 [==============================] - 3s 909us/step - loss: 0.8376 - acc: 0.6999 - val_loss: 0.9229 - val_acc: 0.6822\n",
      "Epoch 11/50\n",
      "3552/3552 [==============================] - 3s 894us/step - loss: 0.8181 - acc: 0.7024 - val_loss: 0.7381 - val_acc: 0.7364\n",
      "Epoch 12/50\n",
      "3552/3552 [==============================] - 3s 913us/step - loss: 0.8089 - acc: 0.7035 - val_loss: 0.7753 - val_acc: 0.7326\n",
      "Epoch 13/50\n",
      "3552/3552 [==============================] - 3s 929us/step - loss: 0.7915 - acc: 0.7134 - val_loss: 0.7788 - val_acc: 0.7364\n",
      "Epoch 14/50\n",
      "3552/3552 [==============================] - 3s 922us/step - loss: 0.7877 - acc: 0.7182 - val_loss: 0.7547 - val_acc: 0.7209\n",
      "Epoch 15/50\n",
      "3552/3552 [==============================] - 3s 911us/step - loss: 0.7683 - acc: 0.7216 - val_loss: 0.7410 - val_acc: 0.7403\n",
      "Epoch 16/50\n",
      "3552/3552 [==============================] - 3s 914us/step - loss: 0.7600 - acc: 0.7176 - val_loss: 0.7518 - val_acc: 0.7326\n",
      "Epoch 17/50\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.7389 - acc: 0.7393 - val_loss: 0.7230 - val_acc: 0.7674\n",
      "Epoch 18/50\n",
      "3552/3552 [==============================] - 3s 929us/step - loss: 0.7081 - acc: 0.7396 - val_loss: 0.7487 - val_acc: 0.7171\n",
      "Epoch 19/50\n",
      "3552/3552 [==============================] - 3s 916us/step - loss: 0.7356 - acc: 0.7382 - val_loss: 0.7221 - val_acc: 0.7519\n",
      "Epoch 20/50\n",
      "3552/3552 [==============================] - 3s 906us/step - loss: 0.7204 - acc: 0.7399 - val_loss: 0.7659 - val_acc: 0.7403\n",
      "Epoch 21/50\n",
      "3552/3552 [==============================] - 3s 911us/step - loss: 0.7115 - acc: 0.7376 - val_loss: 0.7271 - val_acc: 0.7326\n",
      "Epoch 22/50\n",
      "3552/3552 [==============================] - 3s 906us/step - loss: 0.6907 - acc: 0.7508 - val_loss: 0.6751 - val_acc: 0.7558\n",
      "Epoch 23/50\n",
      "3552/3552 [==============================] - 3s 922us/step - loss: 0.6799 - acc: 0.7517 - val_loss: 0.6680 - val_acc: 0.7713\n",
      "Epoch 24/50\n",
      "3552/3552 [==============================] - 3s 931us/step - loss: 0.6780 - acc: 0.7466 - val_loss: 0.6304 - val_acc: 0.7868\n",
      "Epoch 25/50\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.6398 - acc: 0.7630 - val_loss: 0.6797 - val_acc: 0.7713\n",
      "Epoch 26/50\n",
      "3552/3552 [==============================] - 3s 911us/step - loss: 0.6658 - acc: 0.7548 - val_loss: 0.6692 - val_acc: 0.7674\n",
      "Epoch 27/50\n",
      "3552/3552 [==============================] - 3s 922us/step - loss: 0.6501 - acc: 0.7649 - val_loss: 0.6176 - val_acc: 0.7791\n",
      "Epoch 28/50\n",
      "3552/3552 [==============================] - 3s 913us/step - loss: 0.6405 - acc: 0.7666 - val_loss: 0.7479 - val_acc: 0.7403\n",
      "Epoch 29/50\n",
      "3552/3552 [==============================] - 3s 918us/step - loss: 0.6617 - acc: 0.7610 - val_loss: 0.6446 - val_acc: 0.7636\n",
      "Epoch 30/50\n",
      "3552/3552 [==============================] - 3s 921us/step - loss: 0.6329 - acc: 0.7632 - val_loss: 0.5882 - val_acc: 0.7791\n",
      "Epoch 31/50\n",
      "3552/3552 [==============================] - 3s 924us/step - loss: 0.6268 - acc: 0.7669 - val_loss: 0.6094 - val_acc: 0.7829\n",
      "Epoch 32/50\n",
      "3552/3552 [==============================] - 3s 915us/step - loss: 0.6490 - acc: 0.7680 - val_loss: 0.5703 - val_acc: 0.7713\n",
      "Epoch 33/50\n",
      "3552/3552 [==============================] - 3s 916us/step - loss: 0.6374 - acc: 0.7599 - val_loss: 0.6781 - val_acc: 0.7674\n",
      "Epoch 34/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.6300 - acc: 0.7635 - val_loss: 0.6618 - val_acc: 0.7519\n",
      "Epoch 35/50\n",
      "3552/3552 [==============================] - 3s 904us/step - loss: 0.6086 - acc: 0.7804 - val_loss: 0.5859 - val_acc: 0.7946\n",
      "Epoch 36/50\n",
      "3552/3552 [==============================] - 3s 914us/step - loss: 0.6369 - acc: 0.7677 - val_loss: 0.6095 - val_acc: 0.7868\n",
      "Epoch 37/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.6177 - acc: 0.7677 - val_loss: 0.5705 - val_acc: 0.7984\n",
      "Epoch 38/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.6434 - acc: 0.7660 - val_loss: 0.5792 - val_acc: 0.8101\n",
      "Epoch 39/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.6302 - acc: 0.7756 - val_loss: 0.6666 - val_acc: 0.7791\n",
      "Epoch 40/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.6021 - acc: 0.7717 - val_loss: 0.7202 - val_acc: 0.7364\n",
      "Epoch 41/50\n",
      "3552/3552 [==============================] - 3s 906us/step - loss: 0.5846 - acc: 0.7905 - val_loss: 0.5627 - val_acc: 0.7868\n",
      "Epoch 42/50\n",
      "3552/3552 [==============================] - 3s 918us/step - loss: 0.6077 - acc: 0.7807 - val_loss: 0.6195 - val_acc: 0.7674\n",
      "Epoch 43/50\n",
      "3552/3552 [==============================] - 3s 906us/step - loss: 0.5845 - acc: 0.7860 - val_loss: 0.6172 - val_acc: 0.7829\n",
      "Epoch 44/50\n",
      "3552/3552 [==============================] - 3s 903us/step - loss: 0.5644 - acc: 0.7967 - val_loss: 0.5997 - val_acc: 0.7829\n",
      "Epoch 45/50\n",
      "3552/3552 [==============================] - 3s 909us/step - loss: 0.5945 - acc: 0.7810 - val_loss: 0.6791 - val_acc: 0.7674\n",
      "Epoch 46/50\n",
      "3552/3552 [==============================] - 3s 904us/step - loss: 0.5776 - acc: 0.7894 - val_loss: 0.5869 - val_acc: 0.7984\n",
      "Epoch 47/50\n",
      "3552/3552 [==============================] - 3s 910us/step - loss: 0.5658 - acc: 0.7908 - val_loss: 0.5580 - val_acc: 0.7984\n",
      "Epoch 48/50\n",
      "3552/3552 [==============================] - 3s 905us/step - loss: 0.5768 - acc: 0.7824 - val_loss: 0.5997 - val_acc: 0.7946\n",
      "Epoch 49/50\n",
      "3552/3552 [==============================] - 3s 913us/step - loss: 0.5750 - acc: 0.7956 - val_loss: 0.6328 - val_acc: 0.7907\n",
      "Epoch 50/50\n",
      "3552/3552 [==============================] - 3s 920us/step - loss: 0.5846 - acc: 0.7815 - val_loss: 0.6194 - val_acc: 0.7713\n",
      "2\n",
      "Train on 3552 samples, validate on 258 samples\n",
      "Epoch 1/50\n",
      "3552/3552 [==============================] - 10s 3ms/step - loss: 1.6208 - acc: 0.4437 - val_loss: 1.3356 - val_acc: 0.5271\n",
      "Epoch 2/50\n",
      "3552/3552 [==============================] - 3s 954us/step - loss: 0.9456 - acc: 0.6709 - val_loss: 0.8160 - val_acc: 0.7054\n",
      "Epoch 8/50\n",
      "3552/3552 [==============================] - 3s 936us/step - loss: 0.9157 - acc: 0.6729 - val_loss: 0.7474 - val_acc: 0.7558\n",
      "Epoch 9/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.8962 - acc: 0.6802 - val_loss: 0.7550 - val_acc: 0.7558\n",
      "Epoch 10/50\n",
      "3552/3552 [==============================] - 3s 922us/step - loss: 0.8548 - acc: 0.6889 - val_loss: 0.6542 - val_acc: 0.8101\n",
      "Epoch 11/50\n",
      "3552/3552 [==============================] - 3s 937us/step - loss: 0.8476 - acc: 0.6988 - val_loss: 0.6511 - val_acc: 0.7868\n",
      "Epoch 12/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.8244 - acc: 0.7047 - val_loss: 0.6780 - val_acc: 0.7713\n",
      "Epoch 13/50\n",
      "3552/3552 [==============================] - 3s 934us/step - loss: 0.8112 - acc: 0.7030 - val_loss: 0.6810 - val_acc: 0.7558\n",
      "Epoch 14/50\n",
      "3552/3552 [==============================] - 3s 933us/step - loss: 0.7842 - acc: 0.7235 - val_loss: 0.7023 - val_acc: 0.7674\n",
      "Epoch 15/50\n",
      "3552/3552 [==============================] - 3s 911us/step - loss: 0.7902 - acc: 0.7050 - val_loss: 0.6917 - val_acc: 0.7403\n",
      "Epoch 16/50\n",
      "3552/3552 [==============================] - 3s 926us/step - loss: 0.7804 - acc: 0.7221 - val_loss: 0.6551 - val_acc: 0.7713\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552/3552 [==============================] - 3s 944us/step - loss: 0.7712 - acc: 0.7227 - val_loss: 0.5796 - val_acc: 0.8023\n",
      "Epoch 18/50\n",
      "3552/3552 [==============================] - 3s 939us/step - loss: 0.7413 - acc: 0.7385 - val_loss: 0.6293 - val_acc: 0.8023\n",
      "Epoch 19/50\n",
      "3552/3552 [==============================] - 3s 927us/step - loss: 0.7408 - acc: 0.7393 - val_loss: 0.5809 - val_acc: 0.7907\n",
      "Epoch 20/50\n",
      "3552/3552 [==============================] - 3s 916us/step - loss: 0.7157 - acc: 0.7421 - val_loss: 0.5889 - val_acc: 0.8023\n",
      "Epoch 21/50\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 0.7136 - acc: 0.7458 - val_loss: 0.5889 - val_acc: 0.8295\n",
      "Epoch 22/50\n",
      "3552/3552 [==============================] - 3s 924us/step - loss: 0.7024 - acc: 0.7531 - val_loss: 0.5688 - val_acc: 0.8101\n",
      "Epoch 23/50\n",
      "3552/3552 [==============================] - 3s 924us/step - loss: 0.7141 - acc: 0.7447 - val_loss: 0.5278 - val_acc: 0.8256\n",
      "Epoch 24/50\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 0.6856 - acc: 0.7413 - val_loss: 0.5220 - val_acc: 0.8527\n",
      "Epoch 25/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.6759 - acc: 0.7537 - val_loss: 0.5635 - val_acc: 0.8101\n",
      "Epoch 26/50\n",
      "3552/3552 [==============================] - 3s 936us/step - loss: 0.6537 - acc: 0.7607 - val_loss: 0.5530 - val_acc: 0.8295\n",
      "Epoch 27/50\n",
      "3552/3552 [==============================] - 3s 935us/step - loss: 0.6563 - acc: 0.7584 - val_loss: 0.5723 - val_acc: 0.7907\n",
      "Epoch 28/50\n",
      "3552/3552 [==============================] - 3s 947us/step - loss: 0.6779 - acc: 0.7542 - val_loss: 0.5995 - val_acc: 0.7829\n",
      "Epoch 29/50\n",
      "3552/3552 [==============================] - 3s 939us/step - loss: 0.6623 - acc: 0.7599 - val_loss: 0.5356 - val_acc: 0.8101\n",
      "Epoch 30/50\n",
      "3552/3552 [==============================] - 3s 934us/step - loss: 0.6447 - acc: 0.7624 - val_loss: 0.5207 - val_acc: 0.8217\n",
      "Epoch 31/50\n",
      "3552/3552 [==============================] - 3s 928us/step - loss: 0.6352 - acc: 0.7734 - val_loss: 0.5875 - val_acc: 0.8140\n",
      "Epoch 32/50\n",
      "3552/3552 [==============================] - 3s 937us/step - loss: 0.6361 - acc: 0.7714 - val_loss: 0.5880 - val_acc: 0.7984\n",
      "Epoch 33/50\n",
      "3552/3552 [==============================] - 3s 937us/step - loss: 0.6434 - acc: 0.7714 - val_loss: 0.6060 - val_acc: 0.7907\n",
      "Epoch 34/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.6373 - acc: 0.7660 - val_loss: 0.5899 - val_acc: 0.7946\n",
      "Epoch 35/50\n",
      "3552/3552 [==============================] - 3s 910us/step - loss: 0.6157 - acc: 0.7810 - val_loss: 0.5506 - val_acc: 0.8295\n",
      "Epoch 36/50\n",
      "3552/3552 [==============================] - 3s 915us/step - loss: 0.6173 - acc: 0.7801 - val_loss: 0.5503 - val_acc: 0.8372\n",
      "Epoch 37/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.5855 - acc: 0.7872 - val_loss: 0.5028 - val_acc: 0.8605\n",
      "Epoch 38/50\n",
      "3552/3552 [==============================] - 3s 933us/step - loss: 0.6013 - acc: 0.7784 - val_loss: 0.5460 - val_acc: 0.8372\n",
      "Epoch 39/50\n",
      "3552/3552 [==============================] - 3s 923us/step - loss: 0.5911 - acc: 0.7849 - val_loss: 0.5209 - val_acc: 0.8488\n",
      "Epoch 40/50\n",
      "3552/3552 [==============================] - 3s 936us/step - loss: 0.6161 - acc: 0.7728 - val_loss: 0.4891 - val_acc: 0.8682\n",
      "Epoch 41/50\n",
      "3552/3552 [==============================] - 3s 936us/step - loss: 0.5726 - acc: 0.7855 - val_loss: 0.5375 - val_acc: 0.8101\n",
      "Epoch 42/50\n",
      "3552/3552 [==============================] - 3s 934us/step - loss: 0.5983 - acc: 0.7841 - val_loss: 0.5506 - val_acc: 0.8140\n",
      "Epoch 43/50\n",
      "3552/3552 [==============================] - 3s 932us/step - loss: 0.5981 - acc: 0.7886 - val_loss: 0.5015 - val_acc: 0.8333\n",
      "Epoch 44/50\n",
      "3552/3552 [==============================] - 3s 943us/step - loss: 0.5662 - acc: 0.7931 - val_loss: 0.5228 - val_acc: 0.8333\n",
      "Epoch 45/50\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 0.5713 - acc: 0.7869 - val_loss: 0.5163 - val_acc: 0.8527\n",
      "Epoch 46/50\n",
      "3552/3552 [==============================] - 3s 927us/step - loss: 0.6088 - acc: 0.7736 - val_loss: 0.5479 - val_acc: 0.8217\n",
      "Epoch 47/50\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 0.5851 - acc: 0.7779 - val_loss: 0.5139 - val_acc: 0.8217\n",
      "Epoch 48/50\n",
      "3552/3552 [==============================] - 3s 914us/step - loss: 0.5758 - acc: 0.7905 - val_loss: 0.4506 - val_acc: 0.8760\n",
      "Epoch 49/50\n",
      "1568/3552 [============>.................] - ETA: 1s - loss: 0.5868 - acc: 0.770"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3553/3553 [==============================] - 3s 942us/step - loss: 0.6048 - acc: 0.7703 - val_loss: 0.6174 - val_acc: 0.7821\n",
      "Epoch 47/50\n",
      "3553/3553 [==============================] - 3s 977us/step - loss: 0.6031 - acc: 0.7740 - val_loss: 0.5041 - val_acc: 0.8132\n",
      "Epoch 48/50\n",
      "3553/3553 [==============================] - 3s 964us/step - loss: 0.6207 - acc: 0.7684 - val_loss: 0.5019 - val_acc: 0.8210\n",
      "Epoch 49/50\n",
      "3553/3553 [==============================] - 3s 974us/step - loss: 0.5957 - acc: 0.7715 - val_loss: 0.5142 - val_acc: 0.8210\n",
      "Epoch 50/50\n",
      "3553/3553 [==============================] - 3s 959us/step - loss: 0.6269 - acc: 0.7701 - val_loss: 0.4850 - val_acc: 0.8249\n",
      "4\n",
      "Train on 3554 samples, validate on 256 samples\n",
      "Epoch 1/50\n",
      "3554/3554 [==============================] - 12s 3ms/step - loss: 1.6517 - acc: 0.4218 - val_loss: 1.3882 - val_acc: 0.5898\n",
      "Epoch 2/50\n",
      "3554/3554 [==============================] - 4s 989us/step - loss: 1.2779 - acc: 0.5667 - val_loss: 1.2670 - val_acc: 0.6133\n",
      "Epoch 3/50\n",
      "3554/3554 [==============================] - 3s 972us/step - loss: 1.1919 - acc: 0.5796 - val_loss: 1.1401 - val_acc: 0.6406\n",
      "Epoch 4/50\n",
      "3554/3554 [==============================] - 3s 977us/step - loss: 1.1043 - acc: 0.6092 - val_loss: 1.0661 - val_acc: 0.6562\n",
      "Epoch 5/50\n",
      "3554/3554 [==============================] - 3s 972us/step - loss: 1.0380 - acc: 0.6325 - val_loss: 0.9640 - val_acc: 0.6797\n",
      "Epoch 6/50\n",
      "3554/3554 [==============================] - 3s 960us/step - loss: 1.0042 - acc: 0.6472 - val_loss: 1.0037 - val_acc: 0.6875\n",
      "Epoch 7/50\n",
      "3554/3554 [==============================] - 3s 976us/step - loss: 0.9530 - acc: 0.6677 - val_loss: 0.8954 - val_acc: 0.6797\n",
      "Epoch 8/50\n",
      "3554/3554 [==============================] - 4s 986us/step - loss: 0.9517 - acc: 0.6638 - val_loss: 0.8585 - val_acc: 0.7227\n",
      "Epoch 9/50\n",
      "3554/3554 [==============================] - 3s 984us/step - loss: 0.9079 - acc: 0.6767 - val_loss: 0.8756 - val_acc: 0.6953\n",
      "Epoch 10/50\n",
      "3554/3554 [==============================] - 3s 981us/step - loss: 0.8825 - acc: 0.6750 - val_loss: 0.7882 - val_acc: 0.7500\n",
      "Epoch 11/50\n",
      "3554/3554 [==============================] - 3s 973us/step - loss: 0.8858 - acc: 0.6719 - val_loss: 0.8212 - val_acc: 0.7305\n",
      "Epoch 12/50\n",
      "3554/3554 [==============================] - 4s 985us/step - loss: 0.8682 - acc: 0.6913 - val_loss: 0.7854 - val_acc: 0.7500\n",
      "Epoch 13/50\n",
      "3554/3554 [==============================] - 3s 977us/step - loss: 0.8559 - acc: 0.6880 - val_loss: 0.8100 - val_acc: 0.7461\n",
      "Epoch 14/50\n",
      "3554/3554 [==============================] - 3s 984us/step - loss: 0.8480 - acc: 0.6939 - val_loss: 0.7707 - val_acc: 0.7383\n",
      "Epoch 15/50\n",
      "3554/3554 [==============================] - 4s 988us/step - loss: 0.8015 - acc: 0.7043 - val_loss: 0.7272 - val_acc: 0.7656\n",
      "Epoch 16/50\n",
      "3554/3554 [==============================] - 3s 984us/step - loss: 0.7907 - acc: 0.7124 - val_loss: 0.7125 - val_acc: 0.7344\n",
      "Epoch 17/50\n",
      "3554/3554 [==============================] - 3s 985us/step - loss: 0.8137 - acc: 0.7136 - val_loss: 0.7584 - val_acc: 0.7383\n",
      "Epoch 18/50\n",
      "3554/3554 [==============================] - 4s 987us/step - loss: 0.7887 - acc: 0.7200 - val_loss: 0.6951 - val_acc: 0.7812\n",
      "Epoch 19/50\n",
      "3554/3554 [==============================] - 3s 974us/step - loss: 0.7739 - acc: 0.7248 - val_loss: 0.7163 - val_acc: 0.7344\n",
      "Epoch 20/50\n",
      "3554/3554 [==============================] - 3s 979us/step - loss: 0.7767 - acc: 0.7192 - val_loss: 0.6962 - val_acc: 0.7383\n",
      "Epoch 21/50\n",
      "3554/3554 [==============================] - 4s 991us/step - loss: 0.7646 - acc: 0.7304 - val_loss: 0.7061 - val_acc: 0.7500\n",
      "Epoch 22/50\n",
      "3554/3554 [==============================] - 4s 992us/step - loss: 0.7603 - acc: 0.7259 - val_loss: 0.6916 - val_acc: 0.7773\n",
      "Epoch 23/50\n",
      "3554/3554 [==============================] - 3s 968us/step - loss: 0.7482 - acc: 0.7268 - val_loss: 0.6731 - val_acc: 0.7969\n",
      "Epoch 24/50\n",
      "3554/3554 [==============================] - 3s 984us/step - loss: 0.7335 - acc: 0.7293 - val_loss: 0.6510 - val_acc: 0.7656\n",
      "Epoch 25/50\n",
      "3554/3554 [==============================] - 3s 967us/step - loss: 0.7055 - acc: 0.7459 - val_loss: 0.6403 - val_acc: 0.7930\n",
      "Epoch 26/50\n",
      "3554/3554 [==============================] - 3s 957us/step - loss: 0.7266 - acc: 0.7476 - val_loss: 0.6349 - val_acc: 0.7773\n",
      "Epoch 27/50\n",
      "3554/3554 [==============================] - 3s 982us/step - loss: 0.7361 - acc: 0.7352 - val_loss: 0.6084 - val_acc: 0.7930\n",
      "Epoch 28/50\n",
      "3554/3554 [==============================] - 3s 979us/step - loss: 0.7035 - acc: 0.7462 - val_loss: 0.6458 - val_acc: 0.7852\n",
      "Epoch 29/50\n",
      " 288/3554 [=>............................] - ETA: 3s - loss: 0.7577 - acc: 0.722"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 3s 966us/step - loss: 0.7078 - acc: 0.7499 - val_loss: 0.6414 - val_acc: 0.7734\n",
      "Epoch 34/50\n",
      "3554/3554 [==============================] - 4s 988us/step - loss: 0.6531 - acc: 0.7679 - val_loss: 0.6194 - val_acc: 0.7891\n",
      "Epoch 35/50\n",
      "3554/3554 [==============================] - 3s 977us/step - loss: 0.7018 - acc: 0.7504 - val_loss: 0.6351 - val_acc: 0.7578\n",
      "Epoch 36/50\n",
      "3554/3554 [==============================] - 4s 990us/step - loss: 0.6727 - acc: 0.7575 - val_loss: 0.6661 - val_acc: 0.7773\n",
      "Epoch 37/50\n",
      "3554/3554 [==============================] - 4s 987us/step - loss: 0.6712 - acc: 0.7521 - val_loss: 0.6668 - val_acc: 0.7773\n",
      "Epoch 38/50\n",
      "3554/3554 [==============================] - 4s 999us/step - loss: 0.6289 - acc: 0.7639 - val_loss: 0.6115 - val_acc: 0.8047\n",
      "Epoch 39/50\n",
      "3554/3554 [==============================] - 4s 986us/step - loss: 0.6534 - acc: 0.7651 - val_loss: 0.6238 - val_acc: 0.7930\n",
      "Epoch 40/50\n",
      "3554/3554 [==============================] - 3s 982us/step - loss: 0.6558 - acc: 0.7597 - val_loss: 0.7057 - val_acc: 0.7891\n",
      "Epoch 41/50\n",
      "3554/3554 [==============================] - 3s 980us/step - loss: 0.6261 - acc: 0.7710 - val_loss: 0.5659 - val_acc: 0.7930\n",
      "Epoch 42/50\n",
      "3554/3554 [==============================] - 3s 976us/step - loss: 0.6497 - acc: 0.7597 - val_loss: 0.5718 - val_acc: 0.8008\n",
      "Epoch 43/50\n",
      "3554/3554 [==============================] - 3s 973us/step - loss: 0.6436 - acc: 0.7707 - val_loss: 0.6332 - val_acc: 0.7695\n",
      "Epoch 44/50\n",
      "3554/3554 [==============================] - 3s 973us/step - loss: 0.6528 - acc: 0.7625 - val_loss: 0.6265 - val_acc: 0.7969\n",
      "Epoch 45/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.6365 - acc: 0.7687 - val_loss: 0.5877 - val_acc: 0.7852\n",
      "Epoch 46/50\n",
      "3554/3554 [==============================] - 3s 985us/step - loss: 0.6497 - acc: 0.7603 - val_loss: 0.5797 - val_acc: 0.7891\n",
      "Epoch 47/50\n",
      "3554/3554 [==============================] - 3s 982us/step - loss: 0.6483 - acc: 0.7614 - val_loss: 0.6233 - val_acc: 0.8008\n",
      "Epoch 48/50\n",
      "3554/3554 [==============================] - 3s 981us/step - loss: 0.6043 - acc: 0.7811 - val_loss: 0.5530 - val_acc: 0.8047\n",
      "Epoch 49/50\n",
      "3554/3554 [==============================] - 3s 980us/step - loss: 0.6524 - acc: 0.7614 - val_loss: 0.6379 - val_acc: 0.7969\n",
      "Epoch 50/50\n",
      "3554/3554 [==============================] - 3s 983us/step - loss: 0.6246 - acc: 0.7735 - val_loss: 0.6542 - val_acc: 0.7852\n",
      "5\n",
      "Train on 3554 samples, validate on 256 samples\n",
      "Epoch 1/50\n",
      "3554/3554 [==============================] - 13s 4ms/step - loss: 1.6519 - acc: 0.4330 - val_loss: 1.2764 - val_acc: 0.5156\n",
      "Epoch 2/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 1.3053 - acc: 0.5461 - val_loss: 1.0571 - val_acc: 0.6289\n",
      "Epoch 3/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 1.2005 - acc: 0.5732 - val_loss: 0.9914 - val_acc: 0.6367\n",
      "Epoch 4/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 1.1038 - acc: 0.6125 - val_loss: 0.8850 - val_acc: 0.6836\n",
      "Epoch 5/50\n",
      "3554/3554 [==============================] - 4s 991us/step - loss: 1.0471 - acc: 0.6351 - val_loss: 0.8530 - val_acc: 0.6953\n",
      "Epoch 6/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 1.0344 - acc: 0.6325 - val_loss: 0.8379 - val_acc: 0.7070\n",
      "Epoch 7/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.9573 - acc: 0.6579 - val_loss: 0.8034 - val_acc: 0.7109\n",
      "Epoch 8/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.9388 - acc: 0.6708 - val_loss: 0.7584 - val_acc: 0.7266\n",
      "Epoch 9/50\n",
      "3554/3554 [==============================] - 4s 998us/step - loss: 0.9232 - acc: 0.6742 - val_loss: 0.7777 - val_acc: 0.6992\n",
      "Epoch 10/50\n",
      "3554/3554 [==============================] - 3s 976us/step - loss: 0.8915 - acc: 0.6835 - val_loss: 0.7994 - val_acc: 0.7148\n",
      "Epoch 11/50\n",
      "3554/3554 [==============================] - 4s 996us/step - loss: 0.8847 - acc: 0.6902 - val_loss: 0.7361 - val_acc: 0.7305\n",
      "Epoch 12/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.8429 - acc: 0.6941 - val_loss: 0.7291 - val_acc: 0.7383\n",
      "Epoch 13/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.8436 - acc: 0.7001 - val_loss: 0.6895 - val_acc: 0.7734\n",
      "Epoch 14/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.8283 - acc: 0.6998 - val_loss: 0.6881 - val_acc: 0.7461\n",
      "Epoch 15/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.7959 - acc: 0.7144 - val_loss: 0.6865 - val_acc: 0.7617\n",
      "Epoch 16/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.8020 - acc: 0.7181 - val_loss: 0.7308 - val_acc: 0.7383\n",
      "Epoch 17/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.8070 - acc: 0.7110 - val_loss: 0.6991 - val_acc: 0.7422\n",
      "Epoch 18/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.7746 - acc: 0.7243 - val_loss: 0.6336 - val_acc: 0.7812\n",
      "Epoch 19/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.7623 - acc: 0.7245 - val_loss: 0.6165 - val_acc: 0.7578\n",
      "Epoch 20/50\n",
      "3554/3554 [==============================] - 4s 987us/step - loss: 0.7581 - acc: 0.7307 - val_loss: 0.6069 - val_acc: 0.7617\n",
      "Epoch 21/50\n",
      "3554/3554 [==============================] - 3s 985us/step - loss: 0.7439 - acc: 0.7316 - val_loss: 0.6323 - val_acc: 0.7734\n",
      "Epoch 22/50\n",
      "3554/3554 [==============================] - 4s 987us/step - loss: 0.7725 - acc: 0.7167 - val_loss: 0.6272 - val_acc: 0.7500\n",
      "Epoch 23/50\n",
      "3554/3554 [==============================] - 3s 979us/step - loss: 0.7203 - acc: 0.7448 - val_loss: 0.6094 - val_acc: 0.7891\n",
      "Epoch 24/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.7055 - acc: 0.7434 - val_loss: 0.6033 - val_acc: 0.7812\n",
      "Epoch 25/50\n",
      "3554/3554 [==============================] - 4s 994us/step - loss: 0.7457 - acc: 0.7282 - val_loss: 0.6087 - val_acc: 0.7656\n",
      "Epoch 26/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.7028 - acc: 0.7423 - val_loss: 0.6312 - val_acc: 0.7383\n",
      "Epoch 27/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.7150 - acc: 0.7428 - val_loss: 0.6146 - val_acc: 0.7578\n",
      "Epoch 28/50\n",
      "3554/3554 [==============================] - 3s 978us/step - loss: 0.7038 - acc: 0.7394 - val_loss: 0.5956 - val_acc: 0.7539\n",
      "Epoch 29/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.6841 - acc: 0.7515 - val_loss: 0.6310 - val_acc: 0.7461\n",
      "Epoch 30/50\n",
      "3554/3554 [==============================] - 4s 994us/step - loss: 0.6791 - acc: 0.7563 - val_loss: 0.6400 - val_acc: 0.7383\n",
      "Epoch 31/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.6970 - acc: 0.7425 - val_loss: 0.5817 - val_acc: 0.7734\n",
      "Epoch 32/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6906 - acc: 0.7563 - val_loss: 0.5865 - val_acc: 0.7539\n",
      "Epoch 33/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6837 - acc: 0.7468 - val_loss: 0.5717 - val_acc: 0.7969\n",
      "Epoch 34/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6636 - acc: 0.7566 - val_loss: 0.6027 - val_acc: 0.7773\n",
      "Epoch 35/50\n",
      "3554/3554 [==============================] - 4s 998us/step - loss: 0.6700 - acc: 0.7586 - val_loss: 0.5685 - val_acc: 0.7734\n",
      "Epoch 36/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6720 - acc: 0.7527 - val_loss: 0.5780 - val_acc: 0.7656\n",
      "Epoch 37/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.6651 - acc: 0.7518 - val_loss: 0.6213 - val_acc: 0.7539\n",
      "Epoch 38/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6607 - acc: 0.7515 - val_loss: 0.5676 - val_acc: 0.7812\n",
      "Epoch 39/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6616 - acc: 0.7606 - val_loss: 0.5409 - val_acc: 0.8008\n",
      "Epoch 40/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6447 - acc: 0.7684 - val_loss: 0.5507 - val_acc: 0.7930\n",
      "Epoch 41/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6656 - acc: 0.7558 - val_loss: 0.5964 - val_acc: 0.7695\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3554/3554 [==============================] - 4s 996us/step - loss: 0.6611 - acc: 0.7552 - val_loss: 0.6400 - val_acc: 0.7695\n",
      "Epoch 43/50\n",
      "3554/3554 [==============================] - 4s 990us/step - loss: 0.6470 - acc: 0.7665 - val_loss: 0.5782 - val_acc: 0.7539\n",
      "Epoch 44/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6229 - acc: 0.7738 - val_loss: 0.5853 - val_acc: 0.7695\n",
      "Epoch 45/50\n",
      "3554/3554 [==============================] - 4s 993us/step - loss: 0.6241 - acc: 0.7648 - val_loss: 0.5402 - val_acc: 0.7891\n",
      "Epoch 46/50\n",
      "3554/3554 [==============================] - 4s 986us/step - loss: 0.6213 - acc: 0.7687 - val_loss: 0.5605 - val_acc: 0.7812\n",
      "Epoch 47/50\n",
      "3554/3554 [==============================] - 4s 995us/step - loss: 0.6338 - acc: 0.7710 - val_loss: 0.5453 - val_acc: 0.7891\n",
      "Epoch 48/50\n",
      "3554/3554 [==============================] - 4s 1ms/step - loss: 0.6211 - acc: 0.7735 - val_loss: 0.5655 - val_acc: 0.7891\n",
      "Epoch 49/50\n",
      "3554/3554 [==============================] - 4s 992us/step - loss: 0.6223 - acc: 0.7603 - val_loss: 0.5735 - val_acc: 0.7812\n",
      "Epoch 50/50\n",
      "3554/3554 [==============================] - 4s 988us/step - loss: 0.6294 - acc: 0.7662 - val_loss: 0.5544 - val_acc: 0.7891\n",
      "6\n",
      "Train on 3555 samples, validate on 255 samples\n",
      "Epoch 1/50\n",
      "3555/3555 [==============================] - 15s 4ms/step - loss: 1.6201 - acc: 0.4309 - val_loss: 1.2795 - val_acc: 0.5647\n",
      "Epoch 2/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 1.2810 - acc: 0.5499 - val_loss: 1.0911 - val_acc: 0.6314\n",
      "Epoch 3/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 1.1650 - acc: 0.5932 - val_loss: 1.0048 - val_acc: 0.6392\n",
      "Epoch 4/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 1.0660 - acc: 0.6219 - val_loss: 0.9194 - val_acc: 0.7059\n",
      "Epoch 5/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 1.0395 - acc: 0.6290 - val_loss: 0.8878 - val_acc: 0.6941\n",
      "Epoch 6/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.9906 - acc: 0.6526 - val_loss: 0.8288 - val_acc: 0.7176\n",
      "Epoch 7/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.9463 - acc: 0.6608 - val_loss: 0.8030 - val_acc: 0.7294\n",
      "Epoch 8/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.9041 - acc: 0.6737 - val_loss: 0.7943 - val_acc: 0.7176\n",
      "Epoch 9/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.8859 - acc: 0.6838 - val_loss: 0.7475 - val_acc: 0.7255\n",
      "Epoch 10/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.8563 - acc: 0.6895 - val_loss: 0.7173 - val_acc: 0.7647\n",
      "Epoch 11/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.8560 - acc: 0.6996 - val_loss: 0.7354 - val_acc: 0.7294\n",
      "Epoch 12/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.8395 - acc: 0.6928 - val_loss: 0.6862 - val_acc: 0.7412\n",
      "Epoch 13/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.8320 - acc: 0.7024 - val_loss: 0.6783 - val_acc: 0.7882\n",
      "Epoch 14/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7959 - acc: 0.7077 - val_loss: 0.6670 - val_acc: 0.7451\n",
      "Epoch 15/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7613 - acc: 0.7210 - val_loss: 0.6764 - val_acc: 0.7490\n",
      "Epoch 16/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7849 - acc: 0.7255 - val_loss: 0.7108 - val_acc: 0.7529\n",
      "Epoch 17/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7707 - acc: 0.7269 - val_loss: 0.6790 - val_acc: 0.7569\n",
      "Epoch 18/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7477 - acc: 0.7243 - val_loss: 0.5854 - val_acc: 0.7882\n",
      "Epoch 19/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7421 - acc: 0.7280 - val_loss: 0.6700 - val_acc: 0.7529\n",
      "Epoch 20/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7282 - acc: 0.7398 - val_loss: 0.6000 - val_acc: 0.8118\n",
      "Epoch 21/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7262 - acc: 0.7333 - val_loss: 0.6820 - val_acc: 0.7529\n",
      "Epoch 22/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7325 - acc: 0.7331 - val_loss: 0.6365 - val_acc: 0.7882\n",
      "Epoch 23/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7286 - acc: 0.7418 - val_loss: 0.6005 - val_acc: 0.7725\n",
      "Epoch 24/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7171 - acc: 0.7449 - val_loss: 0.5937 - val_acc: 0.7765\n",
      "Epoch 25/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6996 - acc: 0.7485 - val_loss: 0.6150 - val_acc: 0.8039\n",
      "Epoch 26/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7078 - acc: 0.7468 - val_loss: 0.5891 - val_acc: 0.7961\n",
      "Epoch 27/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7187 - acc: 0.7451 - val_loss: 0.6057 - val_acc: 0.7608\n",
      "Epoch 28/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7020 - acc: 0.7435 - val_loss: 0.5797 - val_acc: 0.7961\n",
      "Epoch 29/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7016 - acc: 0.7477 - val_loss: 0.5282 - val_acc: 0.8196\n",
      "Epoch 30/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6662 - acc: 0.7547 - val_loss: 0.5744 - val_acc: 0.7961\n",
      "Epoch 31/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6683 - acc: 0.7665 - val_loss: 0.5708 - val_acc: 0.7647\n",
      "Epoch 32/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6788 - acc: 0.7556 - val_loss: 0.5354 - val_acc: 0.7922\n",
      "Epoch 33/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6557 - acc: 0.7623 - val_loss: 0.5444 - val_acc: 0.7922\n",
      "Epoch 34/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6435 - acc: 0.7668 - val_loss: 0.5699 - val_acc: 0.7922\n",
      "Epoch 35/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.7091 - acc: 0.7466 - val_loss: 0.5594 - val_acc: 0.8078\n",
      "Epoch 36/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6457 - acc: 0.7615 - val_loss: 0.5275 - val_acc: 0.8275\n",
      "Epoch 37/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6392 - acc: 0.7733 - val_loss: 0.5770 - val_acc: 0.8078\n",
      "Epoch 38/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6653 - acc: 0.7640 - val_loss: 0.5623 - val_acc: 0.8314\n",
      "Epoch 39/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6322 - acc: 0.7623 - val_loss: 0.5901 - val_acc: 0.7686\n",
      "Epoch 40/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6323 - acc: 0.7657 - val_loss: 0.5172 - val_acc: 0.8157\n",
      "Epoch 41/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6188 - acc: 0.7736 - val_loss: 0.5769 - val_acc: 0.7765\n",
      "Epoch 42/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6059 - acc: 0.7778 - val_loss: 0.5062 - val_acc: 0.8000\n",
      "Epoch 43/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5967 - acc: 0.7761 - val_loss: 0.5394 - val_acc: 0.8078\n",
      "Epoch 44/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5945 - acc: 0.7854 - val_loss: 0.5410 - val_acc: 0.8275\n",
      "Epoch 45/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6346 - acc: 0.7654 - val_loss: 0.4963 - val_acc: 0.8314\n",
      "Epoch 46/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5871 - acc: 0.7879 - val_loss: 0.5144 - val_acc: 0.7961\n",
      "Epoch 47/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.6151 - acc: 0.7719 - val_loss: 0.5091 - val_acc: 0.8196\n",
      "Epoch 48/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5865 - acc: 0.7871 - val_loss: 0.4893 - val_acc: 0.8353\n",
      "Epoch 49/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5706 - acc: 0.7949 - val_loss: 0.4643 - val_acc: 0.8392\n",
      "Epoch 50/50\n",
      "3555/3555 [==============================] - 4s 1ms/step - loss: 0.5590 - acc: 0.7944 - val_loss: 0.5057 - val_acc: 0.8314\n",
      "7\n",
      "Train on 3556 samples, validate on 254 samples\n",
      "Epoch 1/50\n",
      "3556/3556 [==============================] - 16s 5ms/step - loss: 1.5905 - acc: 0.4497 - val_loss: 1.2883 - val_acc: 0.5433\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3556/3556 [==============================] - 4s 1ms/step - loss: 1.2803 - acc: 0.5548 - val_loss: 1.1155 - val_acc: 0.6142\n",
      "Epoch 3/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 1.1711 - acc: 0.5914 - val_loss: 1.0317 - val_acc: 0.6142\n",
      "Epoch 4/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 1.0840 - acc: 0.6150 - val_loss: 0.9424 - val_acc: 0.6890\n",
      "Epoch 5/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 1.0405 - acc: 0.6381 - val_loss: 0.9079 - val_acc: 0.6850\n",
      "Epoch 6/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 1.0004 - acc: 0.6521 - val_loss: 0.8686 - val_acc: 0.6969\n",
      "Epoch 7/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.9667 - acc: 0.6580 - val_loss: 1.0862 - val_acc: 0.6299\n",
      "Epoch 8/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.9267 - acc: 0.6701 - val_loss: 0.7195 - val_acc: 0.7717\n",
      "Epoch 9/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.8817 - acc: 0.6881 - val_loss: 0.7263 - val_acc: 0.7520\n",
      "Epoch 10/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.8754 - acc: 0.6828 - val_loss: 0.7451 - val_acc: 0.7480\n",
      "Epoch 11/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.8306 - acc: 0.7058 - val_loss: 0.6893 - val_acc: 0.7559\n",
      "Epoch 12/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.8496 - acc: 0.6971 - val_loss: 0.7812 - val_acc: 0.7402\n",
      "Epoch 13/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.8130 - acc: 0.7005 - val_loss: 0.7117 - val_acc: 0.7638\n",
      "Epoch 14/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7981 - acc: 0.7044 - val_loss: 0.6298 - val_acc: 0.7953\n",
      "Epoch 15/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7786 - acc: 0.7182 - val_loss: 0.6878 - val_acc: 0.7520\n",
      "Epoch 16/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7803 - acc: 0.7126 - val_loss: 0.7099 - val_acc: 0.7756\n",
      "Epoch 17/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7707 - acc: 0.7216 - val_loss: 0.6940 - val_acc: 0.7677\n",
      "Epoch 18/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7576 - acc: 0.7323 - val_loss: 0.7158 - val_acc: 0.7520\n",
      "Epoch 19/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7387 - acc: 0.7340 - val_loss: 0.7546 - val_acc: 0.7638\n",
      "Epoch 20/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7378 - acc: 0.7312 - val_loss: 0.6286 - val_acc: 0.7795\n",
      "Epoch 21/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7331 - acc: 0.7208 - val_loss: 0.6263 - val_acc: 0.7717\n",
      "Epoch 22/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7323 - acc: 0.7298 - val_loss: 0.5980 - val_acc: 0.7992\n",
      "Epoch 23/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7008 - acc: 0.7413 - val_loss: 0.5771 - val_acc: 0.8189\n",
      "Epoch 24/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6751 - acc: 0.7500 - val_loss: 0.5984 - val_acc: 0.7913\n",
      "Epoch 25/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.7112 - acc: 0.7424 - val_loss: 0.6411 - val_acc: 0.8031\n",
      "Epoch 26/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6635 - acc: 0.7652 - val_loss: 0.6256 - val_acc: 0.7874\n",
      "Epoch 27/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6719 - acc: 0.7514 - val_loss: 0.5767 - val_acc: 0.8110\n",
      "Epoch 28/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6998 - acc: 0.7478 - val_loss: 0.5573 - val_acc: 0.8228\n",
      "Epoch 29/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6734 - acc: 0.7545 - val_loss: 0.6187 - val_acc: 0.7953\n",
      "Epoch 30/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6613 - acc: 0.7537 - val_loss: 0.5898 - val_acc: 0.7835\n",
      "Epoch 31/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6624 - acc: 0.7621 - val_loss: 0.5591 - val_acc: 0.8150\n",
      "Epoch 32/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6643 - acc: 0.7494 - val_loss: 0.5714 - val_acc: 0.8189\n",
      "Epoch 33/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6408 - acc: 0.7587 - val_loss: 0.6440 - val_acc: 0.7756\n",
      "Epoch 34/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6242 - acc: 0.7646 - val_loss: 0.6662 - val_acc: 0.8110\n",
      "Epoch 35/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6577 - acc: 0.7545 - val_loss: 0.5754 - val_acc: 0.8031\n",
      "Epoch 36/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6385 - acc: 0.7596 - val_loss: 0.6108 - val_acc: 0.8110\n",
      "Epoch 37/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6352 - acc: 0.7576 - val_loss: 0.5464 - val_acc: 0.8268\n",
      "Epoch 38/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6193 - acc: 0.7767 - val_loss: 0.5355 - val_acc: 0.8150\n",
      "Epoch 39/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6363 - acc: 0.7632 - val_loss: 0.5365 - val_acc: 0.8189\n",
      "Epoch 40/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6446 - acc: 0.7562 - val_loss: 0.5427 - val_acc: 0.7953\n",
      "Epoch 41/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6276 - acc: 0.7593 - val_loss: 0.5660 - val_acc: 0.8386\n",
      "Epoch 42/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.5908 - acc: 0.7823 - val_loss: 0.5549 - val_acc: 0.8228\n",
      "Epoch 43/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6199 - acc: 0.7702 - val_loss: 0.5948 - val_acc: 0.8031\n",
      "Epoch 44/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6088 - acc: 0.7756 - val_loss: 0.5517 - val_acc: 0.8228\n",
      "Epoch 45/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6234 - acc: 0.7728 - val_loss: 0.5085 - val_acc: 0.8465\n",
      "Epoch 46/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.5911 - acc: 0.7843 - val_loss: 0.6068 - val_acc: 0.8346\n",
      "Epoch 47/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.5907 - acc: 0.7821 - val_loss: 0.6199 - val_acc: 0.8031\n",
      "Epoch 48/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.6223 - acc: 0.7725 - val_loss: 0.6247 - val_acc: 0.8031\n",
      "Epoch 49/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.5889 - acc: 0.7784 - val_loss: 0.5664 - val_acc: 0.8346\n",
      "Epoch 50/50\n",
      "3556/3556 [==============================] - 4s 1ms/step - loss: 0.5860 - acc: 0.7795 - val_loss: 0.6000 - val_acc: 0.8071\n",
      "8\n",
      "Train on 3557 samples, validate on 253 samples\n",
      "Epoch 1/50\n",
      "3557/3557 [==============================] - 18s 5ms/step - loss: 1.5919 - acc: 0.4422 - val_loss: 1.2191 - val_acc: 0.5771\n",
      "Epoch 2/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 1.2810 - acc: 0.5597 - val_loss: 1.0928 - val_acc: 0.6245\n",
      "Epoch 3/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 1.1518 - acc: 0.5988 - val_loss: 0.9580 - val_acc: 0.6680\n",
      "Epoch 4/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 1.0638 - acc: 0.6250 - val_loss: 0.8955 - val_acc: 0.6957\n",
      "Epoch 5/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 1.0058 - acc: 0.6424 - val_loss: 0.8063 - val_acc: 0.7391\n",
      "Epoch 6/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.9525 - acc: 0.6660 - val_loss: 0.7850 - val_acc: 0.7352\n",
      "Epoch 7/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.9302 - acc: 0.6621 - val_loss: 0.8222 - val_acc: 0.7273\n",
      "Epoch 8/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8860 - acc: 0.6888 - val_loss: 0.7404 - val_acc: 0.7549\n",
      "Epoch 9/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8757 - acc: 0.6981 - val_loss: 0.6807 - val_acc: 0.7628\n",
      "Epoch 10/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8370 - acc: 0.6978 - val_loss: 0.7074 - val_acc: 0.7470\n",
      "Epoch 11/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8355 - acc: 0.6933 - val_loss: 0.6726 - val_acc: 0.7747\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8178 - acc: 0.7087 - val_loss: 0.7062 - val_acc: 0.7431\n",
      "Epoch 13/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8126 - acc: 0.7110 - val_loss: 0.6709 - val_acc: 0.7866\n",
      "Epoch 14/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7815 - acc: 0.7206 - val_loss: 0.6148 - val_acc: 0.7984\n",
      "Epoch 15/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.8068 - acc: 0.7124 - val_loss: 0.6306 - val_acc: 0.7945\n",
      "Epoch 16/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7601 - acc: 0.7279 - val_loss: 0.6683 - val_acc: 0.7628\n",
      "Epoch 17/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7461 - acc: 0.7298 - val_loss: 0.5668 - val_acc: 0.8300\n",
      "Epoch 18/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7467 - acc: 0.7321 - val_loss: 0.6305 - val_acc: 0.7984\n",
      "Epoch 19/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7303 - acc: 0.7380 - val_loss: 0.6163 - val_acc: 0.7945\n",
      "Epoch 20/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7396 - acc: 0.7343 - val_loss: 0.5808 - val_acc: 0.8024\n",
      "Epoch 21/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7381 - acc: 0.7315 - val_loss: 0.6122 - val_acc: 0.8024\n",
      "Epoch 22/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7144 - acc: 0.7411 - val_loss: 0.6464 - val_acc: 0.7747\n",
      "Epoch 23/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.7034 - acc: 0.7459 - val_loss: 0.6253 - val_acc: 0.8063\n",
      "Epoch 24/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6735 - acc: 0.7582 - val_loss: 0.6400 - val_acc: 0.7866\n",
      "Epoch 25/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6798 - acc: 0.7520 - val_loss: 0.6621 - val_acc: 0.7787\n",
      "Epoch 26/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6916 - acc: 0.7430 - val_loss: 0.6300 - val_acc: 0.8142\n",
      "Epoch 27/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6721 - acc: 0.7537 - val_loss: 0.5761 - val_acc: 0.8379\n",
      "Epoch 28/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6559 - acc: 0.7574 - val_loss: 0.5902 - val_acc: 0.7708\n",
      "Epoch 29/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6548 - acc: 0.7644 - val_loss: 0.5555 - val_acc: 0.7866\n",
      "Epoch 30/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6538 - acc: 0.7613 - val_loss: 0.5551 - val_acc: 0.8142\n",
      "Epoch 31/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6508 - acc: 0.7636 - val_loss: 0.5441 - val_acc: 0.8419\n",
      "Epoch 32/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6431 - acc: 0.7636 - val_loss: 0.5771 - val_acc: 0.7945\n",
      "Epoch 33/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6399 - acc: 0.7664 - val_loss: 0.5967 - val_acc: 0.8063\n",
      "Epoch 34/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6469 - acc: 0.7650 - val_loss: 0.5813 - val_acc: 0.8103\n",
      "Epoch 35/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6555 - acc: 0.7568 - val_loss: 0.6034 - val_acc: 0.8182\n",
      "Epoch 36/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6394 - acc: 0.7653 - val_loss: 0.6147 - val_acc: 0.7984\n",
      "Epoch 37/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6351 - acc: 0.7717 - val_loss: 0.6070 - val_acc: 0.8300\n",
      "Epoch 38/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6082 - acc: 0.7779 - val_loss: 0.6035 - val_acc: 0.7945\n",
      "Epoch 39/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6094 - acc: 0.7787 - val_loss: 0.5695 - val_acc: 0.8024\n",
      "Epoch 40/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6017 - acc: 0.7841 - val_loss: 0.7349 - val_acc: 0.7747\n",
      "Epoch 41/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6062 - acc: 0.7889 - val_loss: 0.5755 - val_acc: 0.7984\n",
      "Epoch 42/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5871 - acc: 0.7844 - val_loss: 0.5379 - val_acc: 0.8142\n",
      "Epoch 43/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5841 - acc: 0.7821 - val_loss: 0.5213 - val_acc: 0.8063\n",
      "Epoch 44/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5859 - acc: 0.7872 - val_loss: 0.5170 - val_acc: 0.8221\n",
      "Epoch 45/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5770 - acc: 0.7914 - val_loss: 0.5141 - val_acc: 0.8261\n",
      "Epoch 46/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.6103 - acc: 0.7807 - val_loss: 0.5653 - val_acc: 0.7984\n",
      "Epoch 47/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5886 - acc: 0.7838 - val_loss: 0.5231 - val_acc: 0.8221\n",
      "Epoch 48/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5849 - acc: 0.7810 - val_loss: 0.6142 - val_acc: 0.7866\n",
      "Epoch 49/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5781 - acc: 0.7863 - val_loss: 0.6149 - val_acc: 0.8063\n",
      "Epoch 50/50\n",
      "3557/3557 [==============================] - 4s 1ms/step - loss: 0.5425 - acc: 0.7984 - val_loss: 0.5475 - val_acc: 0.8300\n",
      "9\n",
      "Train on 3558 samples, validate on 252 samples\n",
      "Epoch 1/50\n",
      "3558/3558 [==============================] - 20s 6ms/step - loss: 1.6557 - acc: 0.4132 - val_loss: 1.1867 - val_acc: 0.5675\n",
      "Epoch 2/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.3137 - acc: 0.5458 - val_loss: 0.9375 - val_acc: 0.6548\n",
      "Epoch 3/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.1598 - acc: 0.5854 - val_loss: 0.9474 - val_acc: 0.6706\n",
      "Epoch 4/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.1069 - acc: 0.6082 - val_loss: 0.8192 - val_acc: 0.7381\n",
      "Epoch 5/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.0408 - acc: 0.6279 - val_loss: 0.7592 - val_acc: 0.7381\n",
      "Epoch 6/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9846 - acc: 0.6436 - val_loss: 0.7287 - val_acc: 0.7579\n",
      "Epoch 7/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9628 - acc: 0.6535 - val_loss: 0.7335 - val_acc: 0.7619\n",
      "Epoch 8/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9277 - acc: 0.6695 - val_loss: 0.6673 - val_acc: 0.7698\n",
      "Epoch 9/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8961 - acc: 0.6863 - val_loss: 0.6788 - val_acc: 0.7897\n",
      "Epoch 10/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8780 - acc: 0.6892 - val_loss: 0.6310 - val_acc: 0.7778\n",
      "Epoch 11/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8742 - acc: 0.6967 - val_loss: 0.6423 - val_acc: 0.7817\n",
      "Epoch 12/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8770 - acc: 0.6889 - val_loss: 0.5738 - val_acc: 0.8095\n",
      "Epoch 13/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8361 - acc: 0.7029 - val_loss: 0.5735 - val_acc: 0.8175\n",
      "Epoch 14/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8269 - acc: 0.7026 - val_loss: 0.5548 - val_acc: 0.8135\n",
      "Epoch 15/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7793 - acc: 0.7198 - val_loss: 0.5737 - val_acc: 0.8254\n",
      "Epoch 16/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7694 - acc: 0.7212 - val_loss: 0.5590 - val_acc: 0.8214\n",
      "Epoch 17/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7781 - acc: 0.7144 - val_loss: 0.5795 - val_acc: 0.7976\n",
      "Epoch 18/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7733 - acc: 0.7201 - val_loss: 0.5550 - val_acc: 0.8254\n",
      "Epoch 19/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7542 - acc: 0.7271 - val_loss: 0.5150 - val_acc: 0.8214\n",
      "Epoch 20/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7404 - acc: 0.7279 - val_loss: 0.5223 - val_acc: 0.8254\n",
      "Epoch 21/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7169 - acc: 0.7482 - val_loss: 0.5581 - val_acc: 0.7976\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7068 - acc: 0.7411 - val_loss: 0.5168 - val_acc: 0.8016\n",
      "Epoch 23/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7307 - acc: 0.7400 - val_loss: 0.5349 - val_acc: 0.8056\n",
      "Epoch 24/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7384 - acc: 0.7375 - val_loss: 0.5390 - val_acc: 0.8056\n",
      "Epoch 25/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7086 - acc: 0.7434 - val_loss: 0.5205 - val_acc: 0.8294\n",
      "Epoch 26/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6894 - acc: 0.7437 - val_loss: 0.5359 - val_acc: 0.8095\n",
      "Epoch 27/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6794 - acc: 0.7493 - val_loss: 0.5093 - val_acc: 0.8095\n",
      "Epoch 28/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6839 - acc: 0.7485 - val_loss: 0.4917 - val_acc: 0.8294\n",
      "Epoch 29/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6712 - acc: 0.7465 - val_loss: 0.4716 - val_acc: 0.8214\n",
      "Epoch 30/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6734 - acc: 0.7496 - val_loss: 0.5510 - val_acc: 0.8175\n",
      "Epoch 31/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6499 - acc: 0.7634 - val_loss: 0.4948 - val_acc: 0.8373\n",
      "Epoch 32/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6558 - acc: 0.7583 - val_loss: 0.4948 - val_acc: 0.8294\n",
      "Epoch 33/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6454 - acc: 0.7597 - val_loss: 0.4947 - val_acc: 0.8175\n",
      "Epoch 34/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6562 - acc: 0.7600 - val_loss: 0.4839 - val_acc: 0.8413\n",
      "Epoch 35/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6690 - acc: 0.7639 - val_loss: 0.5379 - val_acc: 0.8135\n",
      "Epoch 36/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6352 - acc: 0.7684 - val_loss: 0.5118 - val_acc: 0.8333\n",
      "Epoch 37/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6269 - acc: 0.7712 - val_loss: 0.4874 - val_acc: 0.8254\n",
      "Epoch 38/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6345 - acc: 0.7656 - val_loss: 0.4841 - val_acc: 0.8333\n",
      "Epoch 39/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6497 - acc: 0.7605 - val_loss: 0.5044 - val_acc: 0.8532\n",
      "Epoch 40/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6569 - acc: 0.7566 - val_loss: 0.4877 - val_acc: 0.8373\n",
      "Epoch 41/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6132 - acc: 0.7732 - val_loss: 0.4260 - val_acc: 0.8611\n",
      "Epoch 42/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6259 - acc: 0.7695 - val_loss: 0.4670 - val_acc: 0.8452\n",
      "Epoch 43/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5998 - acc: 0.7827 - val_loss: 0.4376 - val_acc: 0.8571\n",
      "Epoch 44/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6245 - acc: 0.7704 - val_loss: 0.4916 - val_acc: 0.8294\n",
      "Epoch 45/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6282 - acc: 0.7737 - val_loss: 0.5023 - val_acc: 0.8294\n",
      "Epoch 46/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5985 - acc: 0.7782 - val_loss: 0.4767 - val_acc: 0.8452\n",
      "Epoch 47/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5759 - acc: 0.7909 - val_loss: 0.4324 - val_acc: 0.8452\n",
      "Epoch 48/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5862 - acc: 0.7830 - val_loss: 0.4844 - val_acc: 0.8373\n",
      "Epoch 49/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5745 - acc: 0.7920 - val_loss: 0.4415 - val_acc: 0.8413\n",
      "Epoch 50/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6009 - acc: 0.7808 - val_loss: 0.4574 - val_acc: 0.8611\n",
      "10\n",
      "Train on 3558 samples, validate on 252 samples\n",
      "Epoch 1/50\n",
      "3558/3558 [==============================] - 21s 6ms/step - loss: 1.5935 - acc: 0.4323 - val_loss: 1.2975 - val_acc: 0.5278\n",
      "Epoch 2/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.2616 - acc: 0.5660 - val_loss: 1.0956 - val_acc: 0.6270\n",
      "Epoch 3/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.1597 - acc: 0.5925 - val_loss: 0.9381 - val_acc: 0.6825\n",
      "Epoch 4/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.0698 - acc: 0.6105 - val_loss: 0.9638 - val_acc: 0.6706\n",
      "Epoch 5/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9970 - acc: 0.6439 - val_loss: 0.8878 - val_acc: 0.7024\n",
      "Epoch 6/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9982 - acc: 0.6459 - val_loss: 0.8078 - val_acc: 0.7222\n",
      "Epoch 7/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9291 - acc: 0.6672 - val_loss: 0.7811 - val_acc: 0.7421\n",
      "Epoch 8/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8928 - acc: 0.6782 - val_loss: 0.7695 - val_acc: 0.7103\n",
      "Epoch 9/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8759 - acc: 0.6863 - val_loss: 0.7866 - val_acc: 0.7063\n",
      "Epoch 10/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8610 - acc: 0.6948 - val_loss: 0.7370 - val_acc: 0.7063\n",
      "Epoch 11/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8116 - acc: 0.7032 - val_loss: 0.6967 - val_acc: 0.7500\n",
      "Epoch 12/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8003 - acc: 0.7063 - val_loss: 0.7100 - val_acc: 0.7421\n",
      "Epoch 13/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7759 - acc: 0.7133 - val_loss: 0.7126 - val_acc: 0.7183\n",
      "Epoch 14/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7779 - acc: 0.7260 - val_loss: 0.6490 - val_acc: 0.7540\n",
      "Epoch 15/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7607 - acc: 0.7223 - val_loss: 0.6858 - val_acc: 0.7421\n",
      "Epoch 16/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7597 - acc: 0.7232 - val_loss: 0.7126 - val_acc: 0.7421\n",
      "Epoch 17/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7355 - acc: 0.7372 - val_loss: 0.6648 - val_acc: 0.7738\n",
      "Epoch 18/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7130 - acc: 0.7428 - val_loss: 0.5907 - val_acc: 0.7778\n",
      "Epoch 19/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7137 - acc: 0.7383 - val_loss: 0.6043 - val_acc: 0.7619\n",
      "Epoch 20/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7106 - acc: 0.7445 - val_loss: 0.5952 - val_acc: 0.7738\n",
      "Epoch 21/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7170 - acc: 0.7324 - val_loss: 0.6286 - val_acc: 0.7619\n",
      "Epoch 22/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7104 - acc: 0.7470 - val_loss: 0.6491 - val_acc: 0.7421\n",
      "Epoch 23/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7003 - acc: 0.7510 - val_loss: 0.6006 - val_acc: 0.7817\n",
      "Epoch 24/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7137 - acc: 0.7375 - val_loss: 0.6094 - val_acc: 0.7698\n",
      "Epoch 25/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6981 - acc: 0.7400 - val_loss: 0.6317 - val_acc: 0.7579\n",
      "Epoch 26/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6849 - acc: 0.7510 - val_loss: 0.5909 - val_acc: 0.7738\n",
      "Epoch 27/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7070 - acc: 0.7389 - val_loss: 0.6969 - val_acc: 0.7262\n",
      "Epoch 28/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6887 - acc: 0.7558 - val_loss: 0.6485 - val_acc: 0.7381\n",
      "Epoch 29/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6873 - acc: 0.7482 - val_loss: 0.5722 - val_acc: 0.7897\n",
      "Epoch 30/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6507 - acc: 0.7614 - val_loss: 0.6489 - val_acc: 0.7500\n",
      "Epoch 31/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6760 - acc: 0.7544 - val_loss: 0.5846 - val_acc: 0.7738\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6410 - acc: 0.7552 - val_loss: 0.5460 - val_acc: 0.8095\n",
      "Epoch 33/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6503 - acc: 0.7617 - val_loss: 0.5227 - val_acc: 0.8016\n",
      "Epoch 34/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6476 - acc: 0.7583 - val_loss: 0.5549 - val_acc: 0.7857\n",
      "Epoch 35/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6134 - acc: 0.7743 - val_loss: 0.5577 - val_acc: 0.7738\n",
      "Epoch 36/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6472 - acc: 0.7622 - val_loss: 0.5732 - val_acc: 0.7976\n",
      "Epoch 37/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6222 - acc: 0.7718 - val_loss: 0.5962 - val_acc: 0.7778\n",
      "Epoch 38/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6160 - acc: 0.7693 - val_loss: 0.5328 - val_acc: 0.8016\n",
      "Epoch 39/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5992 - acc: 0.7811 - val_loss: 0.5553 - val_acc: 0.7817\n",
      "Epoch 40/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6286 - acc: 0.7709 - val_loss: 0.5613 - val_acc: 0.7738\n",
      "Epoch 41/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6109 - acc: 0.7749 - val_loss: 0.5107 - val_acc: 0.8056\n",
      "Epoch 42/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5902 - acc: 0.7808 - val_loss: 0.5257 - val_acc: 0.7976\n",
      "Epoch 43/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6050 - acc: 0.7749 - val_loss: 0.5328 - val_acc: 0.8016\n",
      "Epoch 44/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5952 - acc: 0.7811 - val_loss: 0.5164 - val_acc: 0.8095\n",
      "Epoch 45/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5928 - acc: 0.7802 - val_loss: 0.5780 - val_acc: 0.7698\n",
      "Epoch 46/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5751 - acc: 0.7850 - val_loss: 0.5463 - val_acc: 0.8095\n",
      "Epoch 47/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5843 - acc: 0.7901 - val_loss: 0.5785 - val_acc: 0.7976\n",
      "Epoch 48/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5753 - acc: 0.7943 - val_loss: 0.5555 - val_acc: 0.8016\n",
      "Epoch 49/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5786 - acc: 0.7915 - val_loss: 0.5247 - val_acc: 0.8135\n",
      "Epoch 50/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5623 - acc: 0.7951 - val_loss: 0.5146 - val_acc: 0.8254\n",
      "11\n",
      "Train on 3558 samples, validate on 252 samples\n",
      "Epoch 1/50\n",
      "3558/3558 [==============================] - 24s 7ms/step - loss: 1.6638 - acc: 0.4165 - val_loss: 1.2057 - val_acc: 0.6032\n",
      "Epoch 2/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.3228 - acc: 0.5419 - val_loss: 1.0643 - val_acc: 0.5913\n",
      "Epoch 3/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.1896 - acc: 0.5866 - val_loss: 0.9624 - val_acc: 0.6548\n",
      "Epoch 4/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.1080 - acc: 0.6020 - val_loss: 0.8630 - val_acc: 0.6746\n",
      "Epoch 5/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.0656 - acc: 0.6180 - val_loss: 0.7661 - val_acc: 0.7222\n",
      "Epoch 6/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 1.0121 - acc: 0.6402 - val_loss: 0.7086 - val_acc: 0.7302\n",
      "Epoch 7/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9452 - acc: 0.6596 - val_loss: 0.6864 - val_acc: 0.7579\n",
      "Epoch 8/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.9166 - acc: 0.6669 - val_loss: 0.6637 - val_acc: 0.7738\n",
      "Epoch 9/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8888 - acc: 0.6827 - val_loss: 0.6982 - val_acc: 0.7341\n",
      "Epoch 10/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8652 - acc: 0.6883 - val_loss: 0.6645 - val_acc: 0.7857\n",
      "Epoch 11/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8259 - acc: 0.6998 - val_loss: 0.6130 - val_acc: 0.7857\n",
      "Epoch 12/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8152 - acc: 0.7035 - val_loss: 0.6032 - val_acc: 0.7778\n",
      "Epoch 13/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.8151 - acc: 0.7074 - val_loss: 0.5923 - val_acc: 0.7857\n",
      "Epoch 14/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7998 - acc: 0.7083 - val_loss: 0.5879 - val_acc: 0.8016\n",
      "Epoch 15/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7934 - acc: 0.7201 - val_loss: 0.6007 - val_acc: 0.7897\n",
      "Epoch 16/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7904 - acc: 0.7156 - val_loss: 0.5636 - val_acc: 0.7897\n",
      "Epoch 17/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7741 - acc: 0.7153 - val_loss: 0.5796 - val_acc: 0.7778\n",
      "Epoch 18/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7547 - acc: 0.7254 - val_loss: 0.5947 - val_acc: 0.7460\n",
      "Epoch 19/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7327 - acc: 0.7397 - val_loss: 0.5618 - val_acc: 0.7976\n",
      "Epoch 20/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7365 - acc: 0.7400 - val_loss: 0.6143 - val_acc: 0.7500\n",
      "Epoch 21/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7508 - acc: 0.7265 - val_loss: 0.5629 - val_acc: 0.8095\n",
      "Epoch 22/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7390 - acc: 0.7336 - val_loss: 0.5530 - val_acc: 0.8016\n",
      "Epoch 23/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.7034 - acc: 0.7445 - val_loss: 0.5065 - val_acc: 0.8254\n",
      "Epoch 24/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6960 - acc: 0.7448 - val_loss: 0.5399 - val_acc: 0.8214\n",
      "Epoch 25/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6971 - acc: 0.7397 - val_loss: 0.5121 - val_acc: 0.8413\n",
      "Epoch 26/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6845 - acc: 0.7470 - val_loss: 0.5191 - val_acc: 0.8056\n",
      "Epoch 27/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6729 - acc: 0.7513 - val_loss: 0.5109 - val_acc: 0.8214\n",
      "Epoch 28/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6888 - acc: 0.7510 - val_loss: 0.4608 - val_acc: 0.8452\n",
      "Epoch 29/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6503 - acc: 0.7574 - val_loss: 0.5011 - val_acc: 0.8175\n",
      "Epoch 30/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6637 - acc: 0.7530 - val_loss: 0.4712 - val_acc: 0.8333\n",
      "Epoch 31/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6607 - acc: 0.7544 - val_loss: 0.5123 - val_acc: 0.8214\n",
      "Epoch 32/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6615 - acc: 0.7546 - val_loss: 0.4582 - val_acc: 0.8452\n",
      "Epoch 33/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6440 - acc: 0.7723 - val_loss: 0.4766 - val_acc: 0.8532\n",
      "Epoch 34/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6658 - acc: 0.7574 - val_loss: 0.4615 - val_acc: 0.8175\n",
      "Epoch 35/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6491 - acc: 0.7597 - val_loss: 0.5021 - val_acc: 0.8333\n",
      "Epoch 36/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6365 - acc: 0.7645 - val_loss: 0.5128 - val_acc: 0.8135\n",
      "Epoch 37/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6420 - acc: 0.7693 - val_loss: 0.4807 - val_acc: 0.8452\n",
      "Epoch 38/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6115 - acc: 0.7709 - val_loss: 0.5054 - val_acc: 0.8294\n",
      "Epoch 39/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6373 - acc: 0.7676 - val_loss: 0.4780 - val_acc: 0.8492\n",
      "Epoch 40/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6138 - acc: 0.7737 - val_loss: 0.4986 - val_acc: 0.8333\n",
      "Epoch 41/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6636 - acc: 0.7572 - val_loss: 0.4971 - val_acc: 0.8214\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6287 - acc: 0.7749 - val_loss: 0.4419 - val_acc: 0.8373\n",
      "Epoch 43/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6289 - acc: 0.7721 - val_loss: 0.4361 - val_acc: 0.8690\n",
      "Epoch 44/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6172 - acc: 0.7749 - val_loss: 0.4646 - val_acc: 0.8690\n",
      "Epoch 45/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6125 - acc: 0.7788 - val_loss: 0.5101 - val_acc: 0.8095\n",
      "Epoch 46/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5824 - acc: 0.7892 - val_loss: 0.4347 - val_acc: 0.8294\n",
      "Epoch 47/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5891 - acc: 0.7782 - val_loss: 0.4589 - val_acc: 0.8373\n",
      "Epoch 48/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6207 - acc: 0.7791 - val_loss: 0.4712 - val_acc: 0.8333\n",
      "Epoch 49/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.6100 - acc: 0.7760 - val_loss: 0.4640 - val_acc: 0.8452\n",
      "Epoch 50/50\n",
      "3558/3558 [==============================] - 4s 1ms/step - loss: 0.5605 - acc: 0.7943 - val_loss: 0.4129 - val_acc: 0.8532\n",
      "12\n",
      "Train on 3560 samples, validate on 250 samples\n",
      "Epoch 1/50\n",
      "3560/3560 [==============================] - 26s 7ms/step - loss: 1.6388 - acc: 0.4264 - val_loss: 1.3248 - val_acc: 0.5320\n",
      "Epoch 2/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.2610 - acc: 0.5621 - val_loss: 1.2777 - val_acc: 0.5480\n",
      "Epoch 3/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.1277 - acc: 0.6118 - val_loss: 1.0418 - val_acc: 0.6520\n",
      "Epoch 4/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.0493 - acc: 0.6301 - val_loss: 0.9709 - val_acc: 0.6800\n",
      "Epoch 5/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9885 - acc: 0.6449 - val_loss: 0.9749 - val_acc: 0.6640\n",
      "Epoch 6/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9550 - acc: 0.6548 - val_loss: 0.9246 - val_acc: 0.6720\n",
      "Epoch 7/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9381 - acc: 0.6640 - val_loss: 0.9163 - val_acc: 0.7000\n",
      "Epoch 8/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9072 - acc: 0.6854 - val_loss: 0.8374 - val_acc: 0.6880\n",
      "Epoch 9/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8646 - acc: 0.6969 - val_loss: 0.8596 - val_acc: 0.6920\n",
      "Epoch 10/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8236 - acc: 0.7146 - val_loss: 0.8635 - val_acc: 0.6960\n",
      "Epoch 11/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8196 - acc: 0.7115 - val_loss: 0.8114 - val_acc: 0.7200\n",
      "Epoch 12/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7948 - acc: 0.7149 - val_loss: 0.7787 - val_acc: 0.7560\n",
      "Epoch 13/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7984 - acc: 0.7138 - val_loss: 0.8247 - val_acc: 0.7120\n",
      "Epoch 14/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7668 - acc: 0.7225 - val_loss: 0.7965 - val_acc: 0.7400\n",
      "Epoch 15/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7527 - acc: 0.7228 - val_loss: 0.7728 - val_acc: 0.7400\n",
      "Epoch 16/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7682 - acc: 0.7270 - val_loss: 0.7391 - val_acc: 0.7320\n",
      "Epoch 17/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7430 - acc: 0.7343 - val_loss: 0.7728 - val_acc: 0.7680\n",
      "Epoch 18/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7219 - acc: 0.7427 - val_loss: 0.7818 - val_acc: 0.7320\n",
      "Epoch 19/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7481 - acc: 0.7267 - val_loss: 0.7418 - val_acc: 0.7720\n",
      "Epoch 20/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7250 - acc: 0.7376 - val_loss: 0.7156 - val_acc: 0.7760\n",
      "Epoch 21/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6895 - acc: 0.7511 - val_loss: 0.7053 - val_acc: 0.7720\n",
      "Epoch 22/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6894 - acc: 0.7435 - val_loss: 0.7348 - val_acc: 0.7400\n",
      "Epoch 23/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6812 - acc: 0.7590 - val_loss: 0.7788 - val_acc: 0.7440\n",
      "Epoch 24/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6819 - acc: 0.7449 - val_loss: 0.7322 - val_acc: 0.7560\n",
      "Epoch 25/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6713 - acc: 0.7503 - val_loss: 0.6993 - val_acc: 0.7800\n",
      "Epoch 26/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6571 - acc: 0.7632 - val_loss: 0.7376 - val_acc: 0.7560\n",
      "Epoch 27/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6479 - acc: 0.7610 - val_loss: 0.6767 - val_acc: 0.7720\n",
      "Epoch 28/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6489 - acc: 0.7590 - val_loss: 0.6971 - val_acc: 0.7480\n",
      "Epoch 29/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6488 - acc: 0.7697 - val_loss: 0.8756 - val_acc: 0.7280\n",
      "Epoch 30/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6534 - acc: 0.7576 - val_loss: 0.9044 - val_acc: 0.7160\n",
      "Epoch 31/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6381 - acc: 0.7629 - val_loss: 0.6955 - val_acc: 0.7640\n",
      "Epoch 32/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6248 - acc: 0.7660 - val_loss: 0.6433 - val_acc: 0.7840\n",
      "Epoch 33/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6371 - acc: 0.7713 - val_loss: 0.6399 - val_acc: 0.8000\n",
      "Epoch 34/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6277 - acc: 0.7694 - val_loss: 0.6636 - val_acc: 0.8080\n",
      "Epoch 35/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6108 - acc: 0.7753 - val_loss: 0.6543 - val_acc: 0.7560\n",
      "Epoch 36/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6026 - acc: 0.7739 - val_loss: 0.6371 - val_acc: 0.8000\n",
      "Epoch 37/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6114 - acc: 0.7803 - val_loss: 0.7073 - val_acc: 0.7560\n",
      "Epoch 38/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6039 - acc: 0.7756 - val_loss: 0.7656 - val_acc: 0.7080\n",
      "Epoch 39/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6094 - acc: 0.7699 - val_loss: 0.5951 - val_acc: 0.8120\n",
      "Epoch 40/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6045 - acc: 0.7767 - val_loss: 0.6391 - val_acc: 0.7840\n",
      "Epoch 41/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6124 - acc: 0.7742 - val_loss: 0.6298 - val_acc: 0.8080\n",
      "Epoch 42/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5916 - acc: 0.7767 - val_loss: 0.7025 - val_acc: 0.7640\n",
      "Epoch 43/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5773 - acc: 0.7955 - val_loss: 0.6364 - val_acc: 0.7880\n",
      "Epoch 44/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5892 - acc: 0.7888 - val_loss: 0.6169 - val_acc: 0.7880\n",
      "Epoch 45/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5644 - acc: 0.7899 - val_loss: 0.6055 - val_acc: 0.8200\n",
      "Epoch 46/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5777 - acc: 0.7888 - val_loss: 0.6114 - val_acc: 0.7960\n",
      "Epoch 47/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5630 - acc: 0.8031 - val_loss: 0.6765 - val_acc: 0.7720\n",
      "Epoch 48/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5683 - acc: 0.7969 - val_loss: 0.6428 - val_acc: 0.8040\n",
      "Epoch 49/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5609 - acc: 0.7963 - val_loss: 0.6664 - val_acc: 0.7840\n",
      "Epoch 50/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5652 - acc: 0.7952 - val_loss: 0.7025 - val_acc: 0.7640\n",
      "13\n",
      "Train on 3560 samples, validate on 250 samples\n",
      "Epoch 1/50\n",
      "3560/3560 [==============================] - 27s 8ms/step - loss: 1.6419 - acc: 0.4180 - val_loss: 1.3251 - val_acc: 0.5280\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.2962 - acc: 0.5458 - val_loss: 1.2060 - val_acc: 0.5480\n",
      "Epoch 3/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.1829 - acc: 0.5893 - val_loss: 1.0010 - val_acc: 0.6400\n",
      "Epoch 4/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.0978 - acc: 0.6070 - val_loss: 0.9402 - val_acc: 0.6840\n",
      "Epoch 5/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 1.0452 - acc: 0.6309 - val_loss: 0.9071 - val_acc: 0.6720\n",
      "Epoch 6/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9833 - acc: 0.6514 - val_loss: 0.7855 - val_acc: 0.7240\n",
      "Epoch 7/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9658 - acc: 0.6632 - val_loss: 0.7830 - val_acc: 0.7280\n",
      "Epoch 8/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.9291 - acc: 0.6674 - val_loss: 0.7118 - val_acc: 0.7600\n",
      "Epoch 9/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8991 - acc: 0.6787 - val_loss: 0.6754 - val_acc: 0.7800\n",
      "Epoch 10/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8750 - acc: 0.6837 - val_loss: 0.6537 - val_acc: 0.7680\n",
      "Epoch 11/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8588 - acc: 0.6893 - val_loss: 0.7588 - val_acc: 0.7400\n",
      "Epoch 12/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8488 - acc: 0.6978 - val_loss: 0.6300 - val_acc: 0.7840\n",
      "Epoch 13/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8128 - acc: 0.7065 - val_loss: 0.6263 - val_acc: 0.7800\n",
      "Epoch 14/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.8211 - acc: 0.7031 - val_loss: 0.6517 - val_acc: 0.7720\n",
      "Epoch 15/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7611 - acc: 0.7278 - val_loss: 0.5898 - val_acc: 0.7920\n",
      "Epoch 16/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7679 - acc: 0.7228 - val_loss: 0.6942 - val_acc: 0.7200\n",
      "Epoch 17/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7845 - acc: 0.7205 - val_loss: 0.6075 - val_acc: 0.7880\n",
      "Epoch 18/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7572 - acc: 0.7289 - val_loss: 0.5676 - val_acc: 0.8040\n",
      "Epoch 19/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7253 - acc: 0.7365 - val_loss: 0.5408 - val_acc: 0.8120\n",
      "Epoch 20/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7028 - acc: 0.7399 - val_loss: 0.4952 - val_acc: 0.8240\n",
      "Epoch 21/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7376 - acc: 0.7348 - val_loss: 0.5762 - val_acc: 0.7920\n",
      "Epoch 22/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7143 - acc: 0.7494 - val_loss: 0.5355 - val_acc: 0.7920\n",
      "Epoch 23/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6826 - acc: 0.7590 - val_loss: 0.5463 - val_acc: 0.8000\n",
      "Epoch 24/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7103 - acc: 0.7385 - val_loss: 0.5764 - val_acc: 0.8000\n",
      "Epoch 25/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7059 - acc: 0.7514 - val_loss: 0.5871 - val_acc: 0.7840\n",
      "Epoch 26/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.7129 - acc: 0.7410 - val_loss: 0.5985 - val_acc: 0.7760\n",
      "Epoch 27/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6862 - acc: 0.7494 - val_loss: 0.4996 - val_acc: 0.8080\n",
      "Epoch 28/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6514 - acc: 0.7565 - val_loss: 0.4694 - val_acc: 0.8520\n",
      "Epoch 29/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6525 - acc: 0.7632 - val_loss: 0.6097 - val_acc: 0.7840\n",
      "Epoch 30/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6511 - acc: 0.7629 - val_loss: 0.4997 - val_acc: 0.8400\n",
      "Epoch 31/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6659 - acc: 0.7556 - val_loss: 0.4998 - val_acc: 0.8360\n",
      "Epoch 32/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6526 - acc: 0.7621 - val_loss: 0.4909 - val_acc: 0.8160\n",
      "Epoch 33/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6290 - acc: 0.7750 - val_loss: 0.4805 - val_acc: 0.8280\n",
      "Epoch 34/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6181 - acc: 0.7744 - val_loss: 0.5115 - val_acc: 0.8040\n",
      "Epoch 35/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6304 - acc: 0.7736 - val_loss: 0.5050 - val_acc: 0.8280\n",
      "Epoch 36/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6038 - acc: 0.7795 - val_loss: 0.5282 - val_acc: 0.8240\n",
      "Epoch 37/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6423 - acc: 0.7674 - val_loss: 0.4991 - val_acc: 0.8200\n",
      "Epoch 38/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6031 - acc: 0.7862 - val_loss: 0.5292 - val_acc: 0.7960\n",
      "Epoch 39/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6086 - acc: 0.7691 - val_loss: 0.5573 - val_acc: 0.8080\n",
      "Epoch 40/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6276 - acc: 0.7722 - val_loss: 0.5141 - val_acc: 0.8360\n",
      "Epoch 41/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6082 - acc: 0.7711 - val_loss: 0.4637 - val_acc: 0.8280\n",
      "Epoch 42/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5790 - acc: 0.7896 - val_loss: 0.4942 - val_acc: 0.8160\n",
      "Epoch 43/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5999 - acc: 0.7823 - val_loss: 0.4880 - val_acc: 0.8320\n",
      "Epoch 44/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5979 - acc: 0.7801 - val_loss: 0.5761 - val_acc: 0.8200\n",
      "Epoch 45/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5807 - acc: 0.7860 - val_loss: 0.4699 - val_acc: 0.8240\n",
      "Epoch 46/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5977 - acc: 0.7747 - val_loss: 0.5330 - val_acc: 0.8200\n",
      "Epoch 47/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6039 - acc: 0.7787 - val_loss: 0.5345 - val_acc: 0.8240\n",
      "Epoch 48/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5654 - acc: 0.7952 - val_loss: 0.5135 - val_acc: 0.8280\n",
      "Epoch 49/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.5891 - acc: 0.7871 - val_loss: 0.4681 - val_acc: 0.8400\n",
      "Epoch 50/50\n",
      "3560/3560 [==============================] - 4s 1ms/step - loss: 0.6202 - acc: 0.7764 - val_loss: 0.4854 - val_acc: 0.8480\n",
      "14\n",
      "Train on 3561 samples, validate on 249 samples\n",
      "Epoch 1/50\n",
      "3561/3561 [==============================] - 30s 9ms/step - loss: 1.6329 - acc: 0.4398 - val_loss: 1.3896 - val_acc: 0.5663\n",
      "Epoch 2/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 1.2854 - acc: 0.5439 - val_loss: 1.2350 - val_acc: 0.5783\n",
      "Epoch 3/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 1.1614 - acc: 0.5984 - val_loss: 1.1119 - val_acc: 0.6145\n",
      "Epoch 4/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 1.0877 - acc: 0.6133 - val_loss: 1.0457 - val_acc: 0.6586\n",
      "Epoch 5/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.9981 - acc: 0.6389 - val_loss: 0.9667 - val_acc: 0.6787\n",
      "Epoch 6/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.9733 - acc: 0.6481 - val_loss: 1.0212 - val_acc: 0.6667\n",
      "Epoch 7/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.9279 - acc: 0.6681 - val_loss: 0.9200 - val_acc: 0.6747\n",
      "Epoch 8/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.9115 - acc: 0.6726 - val_loss: 0.9009 - val_acc: 0.6667\n",
      "Epoch 9/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.8736 - acc: 0.6900 - val_loss: 0.7845 - val_acc: 0.7189\n",
      "Epoch 10/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.8478 - acc: 0.6928 - val_loss: 0.7344 - val_acc: 0.7430\n",
      "Epoch 11/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.8201 - acc: 0.7004 - val_loss: 0.7600 - val_acc: 0.7510\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.8117 - acc: 0.7102 - val_loss: 0.6939 - val_acc: 0.7671\n",
      "Epoch 13/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7819 - acc: 0.7155 - val_loss: 0.7402 - val_acc: 0.7349\n",
      "Epoch 14/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7672 - acc: 0.7231 - val_loss: 0.7918 - val_acc: 0.7470\n",
      "Epoch 15/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7711 - acc: 0.7206 - val_loss: 0.7325 - val_acc: 0.7590\n",
      "Epoch 16/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7551 - acc: 0.7256 - val_loss: 0.7123 - val_acc: 0.7590\n",
      "Epoch 17/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7456 - acc: 0.7408 - val_loss: 0.6838 - val_acc: 0.7550\n",
      "Epoch 18/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7682 - acc: 0.7209 - val_loss: 0.7118 - val_acc: 0.7470\n",
      "Epoch 19/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7169 - acc: 0.7346 - val_loss: 0.6821 - val_acc: 0.7791\n",
      "Epoch 20/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7181 - acc: 0.7445 - val_loss: 0.7061 - val_acc: 0.7510\n",
      "Epoch 21/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7105 - acc: 0.7450 - val_loss: 0.6536 - val_acc: 0.7590\n",
      "Epoch 22/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7217 - acc: 0.7338 - val_loss: 0.6504 - val_acc: 0.7711\n",
      "Epoch 23/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6756 - acc: 0.7596 - val_loss: 0.6897 - val_acc: 0.7631\n",
      "Epoch 24/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7060 - acc: 0.7442 - val_loss: 0.6120 - val_acc: 0.8072\n",
      "Epoch 25/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.7054 - acc: 0.7386 - val_loss: 0.5937 - val_acc: 0.8153\n",
      "Epoch 26/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6889 - acc: 0.7442 - val_loss: 0.6464 - val_acc: 0.7791\n",
      "Epoch 27/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6801 - acc: 0.7605 - val_loss: 0.6317 - val_acc: 0.8032\n",
      "Epoch 28/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6417 - acc: 0.7621 - val_loss: 0.6172 - val_acc: 0.8072\n",
      "Epoch 29/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6600 - acc: 0.7655 - val_loss: 0.6267 - val_acc: 0.8032\n",
      "Epoch 30/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6517 - acc: 0.7627 - val_loss: 0.6169 - val_acc: 0.7912\n",
      "Epoch 31/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6571 - acc: 0.7591 - val_loss: 0.6310 - val_acc: 0.7791\n",
      "Epoch 32/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6270 - acc: 0.7717 - val_loss: 0.6720 - val_acc: 0.7791\n",
      "Epoch 33/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6499 - acc: 0.7607 - val_loss: 0.5941 - val_acc: 0.7952\n",
      "Epoch 34/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6225 - acc: 0.7759 - val_loss: 0.6149 - val_acc: 0.7912\n",
      "Epoch 35/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6363 - acc: 0.7661 - val_loss: 0.6561 - val_acc: 0.7711\n",
      "Epoch 36/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6372 - acc: 0.7650 - val_loss: 0.5509 - val_acc: 0.8153\n",
      "Epoch 37/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6030 - acc: 0.7787 - val_loss: 0.6087 - val_acc: 0.7912\n",
      "Epoch 38/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5994 - acc: 0.7860 - val_loss: 0.6473 - val_acc: 0.7992\n",
      "Epoch 39/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5827 - acc: 0.7832 - val_loss: 0.6184 - val_acc: 0.8072\n",
      "Epoch 40/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6155 - acc: 0.7765 - val_loss: 0.5873 - val_acc: 0.8072\n",
      "Epoch 41/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5851 - acc: 0.7770 - val_loss: 0.6487 - val_acc: 0.7871\n",
      "Epoch 42/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6051 - acc: 0.7843 - val_loss: 0.6564 - val_acc: 0.7671\n",
      "Epoch 43/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.6106 - acc: 0.7784 - val_loss: 0.6165 - val_acc: 0.7831\n",
      "Epoch 44/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5924 - acc: 0.7826 - val_loss: 0.5982 - val_acc: 0.7992\n",
      "Epoch 45/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5833 - acc: 0.7930 - val_loss: 0.6365 - val_acc: 0.7912\n",
      "Epoch 46/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5930 - acc: 0.7793 - val_loss: 0.6625 - val_acc: 0.7952\n",
      "Epoch 47/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5935 - acc: 0.7863 - val_loss: 0.6316 - val_acc: 0.7871\n",
      "Epoch 48/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5584 - acc: 0.8034 - val_loss: 0.6129 - val_acc: 0.7831\n",
      "Epoch 49/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5718 - acc: 0.7899 - val_loss: 0.6429 - val_acc: 0.7831\n",
      "Epoch 50/50\n",
      "3561/3561 [==============================] - 4s 1ms/step - loss: 0.5674 - acc: 0.7899 - val_loss: 0.5809 - val_acc: 0.8032\n"
     ]
    }
   ],
   "source": [
    "te = [test[:,i] for i in range(10)]\n",
    "te.append(test_smooth)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=15, shuffle=True, random_state=0)\n",
    "oof = np.zeros((len(X), 9))\n",
    "test_predictions = np.zeros((len(test), 9))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X,np.argmax(Y, axis=1))):\n",
    "    print(fold_)\n",
    "    X_train, X_test = X[trn_idx], X[val_idx]\n",
    "    y_train, y_test = Y[trn_idx], Y[val_idx]\n",
    "    X_smooth_train, X_smooth_test = X_smooth[trn_idx], X_smooth[val_idx]\n",
    "    \n",
    "    #The model needs a list of inputs. The code beneath this creates a column-input for each unique column in the training set and appends it to the list. \n",
    "    X_tr = [X_train[:,i] for i in range(10)]\n",
    "    X_tr.append(X_smooth_train)\n",
    "    X_te = [X_test[:,i] for i in range(10)]\n",
    "    X_te.append(X_smooth_test)\n",
    "    \n",
    "    model = init_model()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    model.fit(X_tr, y_train, validation_data = (X_te, y_test), epochs=50, shuffle=True, class_weight=\"balanced\")\n",
    "    pre = model.predict(X_te)\n",
    "    oof[val_idx] = model.predict(X_te)\n",
    "    test_predictions+= model.predict(te)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.75828655e-06 9.10173607e-03 1.33672978e-01 ... 3.23036511e-10\n",
      "  2.00083961e-01 3.27775574e-04]\n",
      " [5.42897530e-01 1.60125344e-01 1.16976081e-02 ... 3.28308030e-03\n",
      "  2.50941830e-03 1.25488497e-02]\n",
      " [2.31603237e-06 6.33470642e-03 1.49466586e-01 ... 6.83435571e-10\n",
      "  5.93096824e-01 9.37274473e-04]\n",
      " ...\n",
      " [1.27595310e-01 1.87077186e-01 1.67241357e-01 ... 5.37498143e-04\n",
      "  7.41873180e-03 1.00979551e-01]\n",
      " [1.47051250e-01 4.03664744e-01 1.11552446e-03 ... 9.64029145e-06\n",
      "  3.00440656e-02 1.67196553e-01]\n",
      " [4.19670059e-02 5.51529306e-03 2.10127875e-03 ... 3.55652082e-06\n",
      "  3.34031521e-03 6.94200329e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class probability predictions need to be converted to a surface text prediction. The code below does exactly that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = np.argmax(test_predictions, axis=1)\n",
    "true = np.argmax(y_test, axis=1)\n",
    "\n",
    "labels = {\n",
    "    0:\"carpet\",\n",
    "    1:\"concrete\",\n",
    "    2:\"fine_concrete\",\n",
    "    3:\"hard_tiles\",\n",
    "    4:\"hard_tiles_large_space\",\n",
    "    5:\"soft_pvc\",\n",
    "    6:\"soft_tiles\",\n",
    "    7:\"tiled\",\n",
    "    8:\"wood\"\n",
    "}\n",
    "\n",
    "pre = []\n",
    "for p in predictions:\n",
    "    pre.append(labels[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub[\"surface\"] = np.array(pre)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
